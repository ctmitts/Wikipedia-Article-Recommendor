{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import request_category as rc\n",
    "import database as db\n",
    "from download import download\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#db.clear_table( 'pages' )\n",
    "#db.clear_table( 'categories' )\n",
    "#db.clear_table( 'subcategories' )\n",
    "#db.clear_table( 'page_category' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#download( ['machine learning'], depth = 0) \n",
    "#download( ['business software'], depth = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.query_to_dataframe( 'SELECT COUNT(*) FROM pages;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.query_to_dataframe( 'SELECT COUNT(*) FROM categories;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.query_to_dataframe( 'SELECT COUNT(*) FROM subcategories;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "db.query_to_dataframe( 'SELECT COUNT(*) FROM page_category;')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles (Non Duplicate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_category_id( category)\n",
    "    query = \"\"\"SELECT category_id \n",
    "               FROM categories \n",
    "               WHERE category = '{}';\"\"\".format( category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"SELECT category, subcategory, subcategory_id \n",
    "   FROM subcategories sc \n",
    "       JOIN categories c \n",
    "       ON sc.category_id = c.category_id \n",
    "   WHERE category ='machine learning' ) as stuff \n",
    "              JOIN page_category pc \n",
    "              ON stuff.subcategory_id = pc.subcategory_id\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_pages_by_category( category, limit = False):\n",
    "    inner_query = \"\"\"SELECT stuff.category, stuff.subcategory, pc.pageid \n",
    "              FROM ( SELECT category, subcategory, subcategory_id \n",
    "                     FROM subcategories sc \n",
    "                         JOIN categories c \n",
    "                         ON sc.category_id = c.category_id \n",
    "                     WHERE category = '{}' ) as stuff \n",
    "              JOIN page_category pc \n",
    "              ON stuff.subcategory_id = pc.subcategory_id\"\"\".format( category)\n",
    "\n",
    "    if limit:\n",
    "        limit = ' LIMIT {}'.format( limit)\n",
    "    else: \n",
    "        limit = ''\n",
    "\n",
    "    pages_query = \"\"\"SELECT crap.category, crap.subcategory, p.title, p.pageid, p.article\n",
    "                        FROM ({}) as crap\n",
    "                        JOIN pages p\n",
    "                        ON crap_ml.pageid = p.pageid{}\"\"\".format( inner_query, limit) \n",
    "    pages_query = re.sub( \"\\s+\",\" \", pages_query)  \n",
    "    return pages_query\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def union_query( *categories):\n",
    "    queries = []\n",
    "    for category in categories:\n",
    "        queries.append( query_pages_by_category( category))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_query = \"\"\"SELECT b.category, b.title, b.pageid, b.article\n",
    "                 FROM (({}) UNION ({}) ) as b;\"\"\".format( ml_pages_query, bs_pages_query)\n",
    "\n",
    "pages_df = db.query_to_dataframe( pages_query)\n",
    "pages_df.shape  # shape = (2425, 3) Before adding category and subcategory\n",
    "                ## shape = (2768, 3) after adding Distinct category and subcategory in outer query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Machine learning - Grab all the unique articles with title and pageid\n",
    "\n",
    "inner_ml = \"\"\"SELECT stuff.category, stuff.subcategory, pc.pageid \n",
    "              FROM ( SELECT category, subcategory, subcategory_id \n",
    "                     FROM subcategories sc \n",
    "                         JOIN categories c \n",
    "                         ON sc.category_id = c.category_id \n",
    "                     WHERE category ='machine learning' ) as stuff \n",
    "              JOIN page_category pc \n",
    "              ON stuff.subcategory_id = pc.subcategory_id             \n",
    "              \"\"\"  #               HAVING COUNT(pc.pageid) = 1 ,        \n",
    "\n",
    "ml_pages_query = \"\"\"SELECT crap_ml.category, p.title, p.pageid, p.article\n",
    "                    FROM ({}) as crap_ml\n",
    "                    JOIN pages p\n",
    "                    ON crap_ml.pageid = p.pageid\n",
    "                    \n",
    "                \"\"\".format( inner_ml) # LIMIT 1000  ## GROUP BY crap_ml.category, crap_ml.subcategory, p.pageid\n",
    "                    #HAVING COUNT( crap_ml.pageid) = 1, DISTINCT,  crap_ml.subcategory,\n",
    "ml_pages_query = re.sub( \"\\s+\",\" \", ml_pages_query)\n",
    "ml_pages_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ml = query_pages_by_category( 'machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT crap_ml.category, p.title, p.pageid, p.article FROM (SELECT stuff.category, stuff.subcategory, pc.pageid FROM ( SELECT category, subcategory, subcategory_id FROM subcategories sc JOIN categories c ON sc.category_id = c.category_id WHERE category ='machine learning' ) as stuff JOIN page_category pc ON stuff.subcategory_id = pc.subcategory_id ) as crap_ml JOIN pages p ON crap_ml.pageid = p.pageid \""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## User This for part 2\n",
    "\n",
    "## Machine learning - Grab all the unique articles with title and pageid\n",
    "\n",
    "inner_ml = \"\"\"SELECT stuff.category, stuff.subcategory, pc.pageid \n",
    "              FROM ( SELECT category, subcategory, subcategory_id \n",
    "                     FROM subcategories sc \n",
    "                         JOIN categories c \n",
    "                         ON sc.category_id = c.category_id \n",
    "                     WHERE category ='machine learning' ) as stuff \n",
    "              JOIN page_category pc \n",
    "              ON stuff.subcategory_id = pc.subcategory_id             \n",
    "              \"\"\"  #               HAVING COUNT(pc.pageid) = 1 ,        \n",
    "\n",
    "ml_pages_query = \"\"\"SELECT crap_ml.category, p.title, p.pageid, p.article\n",
    "                    FROM ({}) as crap_ml\n",
    "                    JOIN pages p\n",
    "                    ON crap_ml.pageid = p.pageid\n",
    "                    \n",
    "                \"\"\".format( inner_ml) # LIMIT 1000  ## GROUP BY crap_ml.category, crap_ml.subcategory, p.pageid\n",
    "                    #HAVING COUNT( crap_ml.pageid) = 1, DISTINCT,  crap_ml.subcategory,\n",
    "ml_pages_query = re.sub( \"\\s+\",\" \", ml_pages_query)\n",
    "ml_pages_query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT crap_bs.category, p.title, p.pageid, p.article FROM (SELECT stuff.category, stuff.subcategory, pc.pageid FROM ( SELECT category, subcategory, subcategory_id FROM subcategories sc JOIN categories c ON sc.category_id = c.category_id WHERE category ='business software' ) as stuff JOIN page_category pc ON stuff.subcategory_id = pc.subcategory_id ) as crap_bs JOIN pages p ON crap_bs.pageid = p.pageid \""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Business Software - Grab all the unique articles with title and pageid\n",
    "#inner_bs = db.category_query( ('\\'business software\\''))\n",
    "inner_bs = \"\"\"SELECT stuff.category, stuff.subcategory, pc.pageid \n",
    "                        FROM ( SELECT category, subcategory, subcategory_id \n",
    "                               FROM subcategories sc \n",
    "                                   JOIN categories c \n",
    "                                   ON sc.category_id = c.category_id \n",
    "                               WHERE category ='business software' ) as stuff \n",
    "                        JOIN page_category pc \n",
    "                        ON stuff.subcategory_id = pc.subcategory_id\n",
    "                        \"\"\"   #  GROUP BY stuff.category, stuff.subcategory, pc.pageid\n",
    "\n",
    "bs_pages_query = \"\"\"SELECT crap_bs.category, p.title, p.pageid, p.article\n",
    "                    FROM ({}) as crap_bs\n",
    "                    JOIN pages p\n",
    "                    ON crap_bs.pageid = p.pageid\n",
    "                    \n",
    "                 \"\"\".format(inner_bs)  ## DISTINCT, LIMIT 1000, HAVING COUNT(crap_bs.pageid) = 1, crap_bs.category, crap_bs.subcategory,\n",
    "bs_pages_query = re.sub( \"\\s+\",\" \", bs_pages_query)\n",
    "bs_pages_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2429, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_query = \"\"\"SELECT b.category, b.title, b.pageid, b.article\n",
    "                 FROM (({}) UNION ({}) ) as b;\"\"\".format( ml_pages_query, bs_pages_query)\n",
    "\n",
    "pages_df = db.query_to_dataframe( pages_query)\n",
    "pages_df.shape  # shape = (2425, 3) Before adding category and subcategory\n",
    "                ## shape = (2768, 3) after adding Distinct category and subcategory in outer query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interesting Observation**:  \n",
    "\n",
    "> At Level 3 there are 6 overlapping articles between categories \n",
    "  \n",
    "> At Level 0 there are 4 overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pages_df.pageid.value_counts() > 1)  ## no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2425, 4)\n"
     ]
    }
   ],
   "source": [
    "pages_df.drop_duplicates( subset = ['pageid'], inplace=True)#.shape  ## No duplicates at Level 0, shape= (2425, 3) Before adding category and subcategory\n",
    "print( pages_df.shape)\n",
    "#pages_df.head()\n",
    "                                                      ## 4 duplicates when category is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create mask for empty articles\n",
    "empty_mask =  pages_df.article == ''\n",
    "print('Articles with no text: {}'.format( sum(empty_mask)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonempty_pages_df = pages_df[~empty_mask].reset_index(drop = True).copy()\n",
    "nonempty_pages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonempty_pages_df.index = nonempty_pages_df.pageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nonempty_pages_df.drop( ['pageid'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NEED TO ADD\n",
    "\n",
    "## pd.concat([gnmoon_wild_df.sentence, document_term_matrix_df], axis=1).sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "min_df (max_df = 1.0)\n",
    "1: 710,350\n",
    "2: 109,838\n",
    "3: 50,844\n",
    "4: 32,388\n",
    "\n",
    "\n",
    "min_df (max_df = .98)\n",
    "1: 710,350\n",
    "2: 109,838\n",
    "3: 50,844\n",
    "4: 32,388\n",
    "\n",
    "min_df (max_df = .80)  only 1 word that is in more than 80% of documents\n",
    "1: 710,349\n",
    "2: 109,837\n",
    "3: 50,843\n",
    "4: 32,387\n",
    "\n",
    "min_df (max_df = .50)  only 6 words that are in more than 50% of documents\n",
    "1: 710,344\n",
    "2: 109,832\n",
    "3: 50,838\n",
    "4: 32,382\n",
    "\n",
    "min_df (max_df = .25)  50 words that are in more than 25% of documents\n",
    "1: 710,300  \n",
    "2: 109,788  \n",
    "3: 50,794   \n",
    "4: 32,382\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n_components: ( min_df = 1, max_df = .9 )\n",
    "\n",
    "100: 0.1337871042008196\n",
    "300: Mem Error\n",
    "500: Mem Error\n",
    "700: Mem Error\n",
    "\n",
    "n_components: ( min_df = 2, max_df = .9 )\n",
    "\n",
    "100: 0.18202407652147967\n",
    "300: 0.32970503832346632\n",
    "500: 0.43948526489396755\n",
    "700: 0.53153148477637313\n",
    "900: 0.61238290794297157\n",
    "1100: 0.68522374099828198\n",
    "\n",
    "n_components: ( min_df = 3, max_df = .9 )\n",
    "\n",
    "100: 0.20782662015281972\n",
    "300: 0.36829866892222235\n",
    "500: 0.48313104548616292\n",
    "700: 0.57643069673627811\n",
    "900: 0.6561758518543539\n",
    "1100: 0.72597046032068679\n",
    "1300: 0.78736200905925902\n",
    "1500: 0.84126804941587563\n",
    "\n",
    "n_components: ( min_df = 4, max_df = .9 )\n",
    "\n",
    "100: 0.22460345539114612\n",
    "300: 0.39272018849478108\n",
    "500: 0.51038330526178433\n",
    "700: 0.60421112472188454\n",
    "900: 0.68293250094820435\n",
    "1100: 0.75054460351346541\n",
    "1300: 0.80890827705048696\n",
    "1500: 0.85913339444585113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonempty_pages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Initialize the TFIDFer object\n",
    "\n",
    "tfidf_er = TfidfVectorizer( ngram_range = (1,2), min_df = 3, max_df = .9, stop_words = 'english') ##  \n",
    "## max_df between .88 and .89, 1 word is removed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit_transform\n",
    "dtm_sparse = tfidf_er.fit_transform( nonempty_pages_df.article )\n",
    "dtm_sparse.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_term_matrix_df = pd.DataFrame(dtm_sparse.toarray(),\n",
    "                                       index=nonempty_pages_df.index, ## index = pageid\n",
    "                                       columns=tfidf_er.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 700\n",
    "SVD = TruncatedSVD(n_components)\n",
    "component_names = [\"component_\"+str(i+1) for i in range(n_components)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST COSINE  (min_df = 3, n_components = 700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sparse dtm\n",
    "\n",
    "#svd_matrix = SVD.fit_transform( dtm_sparse)\n",
    "#svd_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## dtm\n",
    "svd_matrix = SVD.fit_transform( document_term_matrix_df)\n",
    "svd_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(range(n_components), np.cumsum(SVD.explained_variance_ratio_), label='cumulative explained variance')\n",
    "plt.legend()\n",
    "\n",
    "cum_expl_variance = np.cumsum(SVD.explained_variance_ratio_)[-1]\n",
    "cum_expl_variance\n",
    "#SVD.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## use for cosine\n",
    "\n",
    "## add row for search article\n",
    "\n",
    "latent_semantic_analysis = pd.DataFrame(svd_matrix,\n",
    "                                        index=document_term_matrix_df.index,#nonempty_pages_df.pageid,\n",
    "                                        columns=component_names)\n",
    "\n",
    "\n",
    "\n",
    "#latent_semantic_analysis.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_semantic_analysis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSA_mat = nonempty_pages_df[['category', 'title','article']].merge( latent_semantic_analysis, how = 'outer',left_index = True, right_index = True, \n",
    "                                             copy = True, suffixes = ('', ''))\n",
    "\n",
    "#LSA_mat.reset_index( nonempty_pages_df.pageid, drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSA_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cosine_similarity()  ## No Y  dist(x,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis.loc[:,'article'] = nonempty_pages_df.loc[:,'article']\n",
    "latent_semantic_analysis.loc[:,'title'] = nonempty_pages_df[:, 'title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSA_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Article Search - (Make Function)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##search_doc = LSA_mat.sample(1)  # drop(['title','article'], axis = 1).\n",
    "#search_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_doc, pageid = rc.get_article('Saffron Technology')\n",
    "print( pageid )\n",
    "search_doc[0:200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply cleaner\n",
    "\n",
    "search_doc = rc.cleaner( search_doc)\n",
    "search_doc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.array(search_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_sparse = tfidf_er.transform( [search_doc] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "search_svd = SVD.transform( search_sparse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#search\n",
    "\n",
    "search_lsa = pd.DataFrame(search_svd,\n",
    "                            index=[int(pageid)],#nonempty_pages_df.pageid,\n",
    "                                        columns=component_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_lsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LSA_mat = nonempty_pages_df[['category', 'title','article']] \\\n",
    "            .merge( latent_semantic_analysis, how = 'outer',\n",
    "                   left_index = True, right_index = True, \n",
    "                        copy = True, suffixes = ('', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cosine_df = pd.DataFrame( cosine_similarity( LSA_mat.drop(['category','title','article'], axis = 1), search_lsa ), columns = ['cosine'], index = LSA_mat.index)\n",
    "search_cosine_df = nonempty_pages_df[['category', 'title']].merge( search_cosine_df, how = 'outer', left_index = True, right_index = True, copy = True, suffixes = ('', '') )\n",
    "search_cosine_df.index = search_cosine_df.title\n",
    "search_cosine_df.drop( ['title'], axis = 1, inplace = True)\n",
    "search_cosine_df.sort_values(by = 'cosine', ascending=False)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_cosine_df = pd.DataFrame( cosine_similarity( LSA_mat.drop(['category','title','article'], axis = 1), search_lsa ), columns = ['cosine'], index = LSA_mat.index)\n",
    "\n",
    "search_cosine_df.sort_values(by = 'cosine', ascending=False)[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using article from LSA_mat as Search doc\n",
    "\n",
    "search_cosine_df = pd.DataFrame( cosine_similarity( LSA_mat.drop(['category','title','article'], axis = 1), search_doc.drop(['category','title','article'], axis = 1) ), columns = ['cosine'], index = LSA_mat.title)\n",
    "search_cosine_df.sort_values(by = 'cosine', ascending=False)[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_expression = pd.DataFrame(SVD.components_,\n",
    "                                     index=component_names,\n",
    "                                     columns=tfidf_er.get_feature_names()).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(1,11):\n",
    "    vocabulary_expression['abs_component_{}'.format(i)] = np.abs(vocabulary_expression['component_{}'.format(i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf_er.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
