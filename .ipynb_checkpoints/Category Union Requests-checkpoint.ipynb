{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install spacy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from request_categories_old import category_format, grab_content #, format_query, request_elements, get_subcategories, get_pages\n",
    "#import database as db\n",
    "import re\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = 'machine learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_query(category, *ptype ):\n",
    "    '''Category should be provided as a string,  ptype may be page, subcat, or file'''\n",
    "    categoryF = category_format(category)\n",
    "    \n",
    "    ptype_dict = {'page':'0', 'subcat':'14','file':'6'}\n",
    "    if len( ptype) < 2:\n",
    "        nstype = ptype_dict[ ptype]\n",
    "        #print( 'single' + nstype)\n",
    "    else:\n",
    "        p1, p2 = ptype\n",
    "        ptype = p1 + \"|\" + p2\n",
    "        #print( p1, p2)\n",
    "        nstype = ptype_dict[ p1 ] + \"|\" + ptype_dict[ p2 ]\n",
    "        #print( 'double' + nstype)\n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    action_tag = \"?action=query&list=categorymembers&cmlimit=max\" ## fetch all category members (pages, subcategories)\n",
    "    category_tag = '&cmtitle=Category:{}&cmtype={}&cmnamespace={}&format=json'.format( categoryF, ptype, nstype) ## append category to cat_tag\n",
    "    query = base_url + action_tag + category_tag# + parameters_tag ## concatenate base_url with request tags\n",
    "    return query\n",
    "\n",
    "def request_elements( category, *ptype, tag = False):\n",
    "    query = format_query( category, *ptype)\n",
    "    \n",
    "    r = requests.get( query)  ## request HTTP results\n",
    "    response = r.json()\n",
    "    try:\n",
    "        elements_df = pd.DataFrame( response['query']['categorymembers'])\n",
    "        if tag:\n",
    "            elements_df['category'] = tag\n",
    "        return elements_df\n",
    "    except:\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "super_category = 'machine learning'\n",
    "def get_subcategories_tabulate( category,depth=3, category_dict= {}  ):  ## Restrixt depth to level 4\n",
    "    category_pages_df = request_elements( category, 'page', 'subcat', tag = category)\n",
    "    #category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "    #category_dict = { category:[]}\n",
    "    pages_df_list = []\n",
    "    \n",
    "    #category_pages_df_list.append( category_pages_df)\n",
    "    \n",
    "    \n",
    "    if category_pages_df.empty:  ## if category page is empty return empty dictionary   \n",
    "        tabs = tabulate(depth, 1)\n",
    "        print( tabs + 'Empty Category')\n",
    "        return category_dict\n",
    "    else:  # otherwise, lets get separate the articles and sub-categories\n",
    "        #category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "\n",
    "        cat_mask = category_pages_df.title.str.contains( 'Category:')\n",
    "        \n",
    "        pages_df = category_pages_df[~cat_mask]#.copy()  ## Articles listed under category\n",
    "        #category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "        tabs = tabulate(depth, 1)\n",
    "        print( tabs + 'New category: {} added to category_dict'.format(category) )\n",
    "        \n",
    "        #print([ cat for cat in category_dict[category]] )\n",
    "        category_df = category_pages_df[ cat_mask]#.copy()\n",
    "        \n",
    "        if category_df.empty:   ## IF no sub-categories, store the pages_df and move on\n",
    "            category_dict[category] = []\n",
    "            category_dict[category] = pages_df  ## append pages_df to category_dict list for category\n",
    "            \n",
    "            tabs = tabulate(depth, 3)\n",
    "            print( tabs + '{} has NO SUBCATEGORIES'.format( category))\n",
    "            #break\n",
    "            return category_dict\n",
    "        else:  ## Map sub-categories to a list\n",
    "            tabs = tabulate(depth, 1)\n",
    "            print( tabs +'INNER- THERE ARE SUBCATEGORIES')\n",
    "            category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "            category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "            sub_categories = category_df.title.str.replace( 'Category:', '').tolist()  \n",
    "            #print( tabs + '{}'.format(sub_categories) )\n",
    "            ## iterate through subcategories, add pages in subcategories to category pages_df list\n",
    "            \n",
    "            for i, subcat in enumerate(sub_categories[0:5]):  \n",
    "                #category_dict[ subcat] = []\n",
    "                tabs = tabulate(depth, 2)\n",
    "                #try:\n",
    "                if depth < 0:\n",
    "                    break\n",
    "                else:\n",
    "                    tabs = tabulate(depth, 2)\n",
    "                    print( tabs + subcat + ': RECURSIVE CALL at a depth of ' + str(depth) )\n",
    "                    #category_dict[subcat] = []  ## Initialize the key-pair with an empty list\n",
    "                    category_dict[subcat] = get_subcategories( subcat, depth - 1, category_dict) #, category_dict = category_dict\n",
    "                    \n",
    "                    ## After recursive call, append the pages_df returned by the sub-category to the category- pages_df\n",
    "                    #if category_dict[subcat]: \n",
    "                    #if depth \n",
    "                    #try:\n",
    "                        #for child in category_dict[subcat]: ## original\n",
    "                    #    for child in category_dict[subcat]:\n",
    "                            \n",
    "                    #        category_dict[super_category].append( category_dict[subcat])\n",
    "                    #        category_dict[category].append( category_dict[subcat][child])  \n",
    "                    #        print( tabs + 'Adding pages from {} to super-category (children of {})'.format(child, subcat))\n",
    "                    #category_dict['articles'].append( )\n",
    "                    #except:\n",
    "                    #else:\n",
    "                    #    print( tabs + 'No pages to add to super-category from {}: '.format( subcat))\n",
    "                    #    continue\n",
    "            \n",
    "    \n",
    "            return category_dict\n",
    "                        #sub_category_dict = get_subcategories( subcat, depth -1, first_run = False) #, visited = visited                    \n",
    "\n",
    "\n",
    "                        #category_dict[subcat][]\n",
    "                        #category_dict[subcat] = {'parent': category, 'children':sub_category_dict, 'page_info':category_pages  }\n",
    "                        #category_dict[subcat] = \n",
    "                #except:\n",
    "                #    continue\n",
    "\n",
    "            #if depth == 3:    \n",
    "            #    return {category: category_dict}, \n",
    "            #else:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debugging = True\n",
    "\n",
    "def dbg( *args):\n",
    "    if debugging:\n",
    "        print( *args)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaned and working\n",
    "\n",
    "tabulate = lambda x, mod: '\\t'*((3-x) + mod)\n",
    "\n",
    "def get_pages( category, depth=3, category_dict= {}, first_run = True  ):  ## Restrixt depth to level 4\n",
    "    category_pages_df = request_elements( category, 'page', 'subcat', tag = category)\n",
    "    \n",
    "    if first_run:\n",
    "        category_dict.clear()\n",
    "    \n",
    "    if category_pages_df.empty:  ## if category page is empty return empty dictionary\n",
    "        ## Tabulate\n",
    "        tabs = tabulate(depth, 1)\n",
    "        print( tabs + 'Empty Category')\n",
    "        return category_dict\n",
    "    else:  # otherwise, lets separate the articles and sub-categories\n",
    "        ## Tabulate\n",
    "        tabs = tabulate(depth, 1)\n",
    "        print( tabs + 'New category: {} added to category_dict'.format(category) )\n",
    "        cat_mask = category_pages_df.title.str.contains( 'Category:')\n",
    "        category_df = category_pages_df[ cat_mask].copy()       \n",
    "        pages_df = category_pages_df[~cat_mask].copy()  ## Articles listed under category\n",
    "        if category_df.empty:   ## IF the category has NO sub-categories, store the pages_df and move on\n",
    "            ## Tabulate\n",
    "            tabs = tabulate(depth, 3)\n",
    "            print( tabs + '{} has NO SUBCATEGORIES'.format( category))\n",
    "            category_dict[category] = pages_df \n",
    "            return category_dict \n",
    "        else:  ## Map sub-categories to a list, create a list to store dataframes for each sub-category\n",
    "            ## Tabulate\n",
    "            tabs = tabulate(depth, 1)\n",
    "            print( tabs +'INNER- THERE ARE SUBCATEGORIES')\n",
    "            sub_categories = category_df.title.str.replace( 'Category:', '').tolist()  \n",
    "            category_dict[category] = []\n",
    "            category_dict[category].append(pages_df)\n",
    "            ## iterate through subcategories, add pages from subcategories to their parent category list of pages_dfs\n",
    "            for i, subcat in enumerate(sub_categories[0:3]):  \n",
    "                if depth < 0:\n",
    "                    break\n",
    "                else:\n",
    "                    ## Tabulate\n",
    "                    tabs = tabulate(depth, 2)\n",
    "                    print( tabs + subcat + ': RECURSIVE CALL at a depth of ' + str(depth) )\n",
    "                    category_dict = get_pages( subcat, depth - 1, first_run = False)\n",
    "                    try:\n",
    "                        if type( category_dict[subcat]) is list:  ## Categories with subcategories may return list for subcategories with nested subcategories\n",
    "                            pages_df_from_category = pd.concat( category_dict[subcat] )  \n",
    "                            pages_df_from_category.loc[:,'category'] = subcat ## Rename the category column to be uniform as super-category\n",
    "                            category_dict[category].append(pages_df_from_category  ) \n",
    "                        else:\n",
    "                            category_dict[category].append( category_dict[subcat] )\n",
    "                    except:         \n",
    "                        continue\n",
    "            try:\n",
    "                category_dict[category] = pd.concat( category_dict[category])\n",
    "                category_dict[category]['category'] = category\n",
    "                return category_dict\n",
    "            except:\n",
    "                return category_dict\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNew category: machine learning added to category_dict\n",
      "\tINNER- THERE ARE SUBCATEGORIES\n",
      "\t\tApplied machine learning: RECURSIVE CALL at a depth of 3\n",
      "\t\tNew category: Applied machine learning added to category_dict\n",
      "\t\t\t\tApplied machine learning has NO SUBCATEGORIES\n",
      "\t\tArtificial neural networks: RECURSIVE CALL at a depth of 3\n",
      "\t\tNew category: Artificial neural networks added to category_dict\n",
      "\t\tINNER- THERE ARE SUBCATEGORIES\n",
      "\t\t\tDeep learning: RECURSIVE CALL at a depth of 2\n",
      "\t\t\tNew category: Deep learning added to category_dict\n",
      "\t\t\t\t\tDeep learning has NO SUBCATEGORIES\n",
      "\t\t\tNeural network software: RECURSIVE CALL at a depth of 2\n",
      "\t\t\tNew category: Neural network software added to category_dict\n",
      "\t\t\t\t\tNeural network software has NO SUBCATEGORIES\n",
      "\t\tBayesian networks: RECURSIVE CALL at a depth of 3\n",
      "\t\tNew category: Bayesian networks added to category_dict\n",
      "\t\t\t\tBayesian networks has NO SUBCATEGORIES\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ml_category_dict = get_pages('machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_category_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_category_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#category_dict['Deep learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = get_pages('')\n",
    "\n",
    "pd.concat( test.values())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Old - without grab_content being optional\n",
    "def fill_pages( category, depth = 3):\n",
    "    \n",
    "    category_dict = get_pages( category, depth)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        category_pages_df = pd.concat( category_dict.values())\n",
    "    \n",
    "        category_pages_df.drop('ns', axis = 1, inplace = True)\n",
    "        category_pages_df.reset_index( drop = True, inplace = True)\n",
    "        \n",
    "        unique_pages_df = category_pages_df.drop_duplicates(subset = ['pageid', 'title']).copy()\n",
    "\n",
    "        unique_pages_df.reset_index( drop = True, inplace = True)\n",
    "\n",
    "        #unique_pages_df['article'] = unique_pages_df.pageid.apply( grab_content )  ## Grab content and clean it\n",
    "        \n",
    "        return category_pages_df, unique_pages_df\n",
    "        \n",
    "        \n",
    "    except:\n",
    "        print( 'Nothing to fill.')\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from spacy.en import STOP_WORDS\n",
    "from spacy.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaner(message):\n",
    "    message = re.sub('\\.+', ' ', message)\n",
    "    message = re.sub('[^a-z0-9 ]',' ', message.lower())\n",
    "\n",
    "    message = re.sub('\\d+','',message)\n",
    "    message = re.sub('\\s+',' ',message)\n",
    "    \n",
    "    message = ' '.join(i.orth_ for i in nlp(message)  ## lemma - original word, ## ortho - root\n",
    "                    if i.orth_ not in STOP_WORDS)\n",
    "    message = ' '.join(message.split())\n",
    "    return message \n",
    "\n",
    "def grab_content( page_id, clean = True):\n",
    "    try:\n",
    "        page_content = wikipedia.WikipediaPage(pageid = page_id).content\n",
    "    except: \n",
    "        page_content = ''\n",
    "    if clean:\n",
    "        return cleaner(page_content)\n",
    "    else:\n",
    "        return page_content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_one_grab = .661189 ## seconds\n",
    "\n",
    "def fill_unique_pages( category, depth = 3, grab = False):\n",
    "    start = datetime.now()\n",
    "    print('Gathering page information from Category: {}, pages from nested sub-categories (+{} levels) will be included as a union for each category. '.format( category, depth))\n",
    "    category_dict = get_pages( category, depth)\n",
    "    n_categories = len( category_dict.keys()) - 1 ## Exclude the original category\n",
    "    print('\\tNested sub-categories: {}'.format( n_categories) )\n",
    "    \n",
    "    try:\n",
    "        category_pages_df = pd.concat( category_dict.values())\n",
    "    \n",
    "        category_pages_df.drop('ns', axis = 1, inplace = True)\n",
    "        category_pages_df.reset_index( drop = True, inplace = True)\n",
    "        \n",
    "        unique_pages_df = category_pages_df.drop_duplicates(subset = ['pageid', 'title']).copy()\n",
    "\n",
    "        unique_pages_df.reset_index( drop = True, inplace = True)\n",
    "        \n",
    "        n_grabs = unique_pages_df.shape[0]\n",
    "        #print( unique_pages_df.shape, n_grabs)\n",
    "        \n",
    "        estT = round(time_of_one_grab*n_grabs/60, 2)  ## minutes\n",
    "        print('\\tRequesting {} unique articles - ETA: {} minutes'.format( n_grabs, estT))\n",
    "        if grab:\n",
    "            unique_pages_df['article'] = unique_pages_df.pageid.apply( grab_content )  ## Grab content and clean it\n",
    "            tag = ''\n",
    "        else:\n",
    "            tag = '(article excluded)'\n",
    "        totT = round((datetime.now()-start).seconds/60,2) ## minutes\n",
    "        print('\\t\\tPage collection {} took a total of {} minutes'.format(tag, totT) )\n",
    "        return category_pages_df, unique_pages_df\n",
    "    \n",
    "    except:\n",
    "        print( 'Nothing to fill.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Do not grab articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_na, unique_pages_df_na = fill_unique_pages('machine learning', depth = 3, grab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_na, unique_pages_df_na = fill_unique_pages('business software', depth = 0, grab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_na, unique_pages_df_na = fill_unique_pages('business software', depth = 1, grab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_na, unique_pages_df_na = fill_unique_pages('business software', depth = 2, grab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_na, unique_pages_df_na = fill_unique_pages('business software', depth = 3, grab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = (datetime.now() - start)\n",
    "diff.seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( round((datetime.now() - start)/60,2) + \" minutes\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df, unique_pages_df = fill_unique_pages('machine learning', depth = 3, grab = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df.shape, unique_pages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_test, unique_pages_df_test = fill_unique_pages('machine learning', depth = 0, grab = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_pages_df_test.shape, unique_pages_df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pages_df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = category_pages_df_test.category.unique().tolist()\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_of_one_grab = .661189\n",
    "print( str( round((time_of_one_grab*888)/60, 2)) + ' minutes' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_content_tester( page_id, clean = True):\n",
    "    \n",
    "    start = datetime.now()\n",
    "    try:\n",
    "        page_content = wikipedia.WikipediaPage(pageid = page_id).content\n",
    "    except: \n",
    "        page_content = ''\n",
    "    if clean:\n",
    "        print( datetime.now() - start)\n",
    "        return cleaner(page_content)\n",
    "    else:\n",
    "        return page_content\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_content_tester( 43385931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_content( 43385931)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import request_cat as rc\n",
    "import database as db\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def download( *category, depth, pickle = False):\n",
    "    \n",
    "    categories = list(*category)\n",
    "    \n",
    "    for cat in categories:\n",
    "        start = datetime.now()\n",
    "        if pickle:\n",
    "            pages_df = pd.read_pickle('./docker/postgres/data/{}'.format( pickle) )\n",
    "        else:\n",
    "            print( \"Collecting Wikipedia pages for Category: {}\".format(category) )\n",
    "            pages_df = rc.get_pages( cat, depth)\n",
    "        #categories_df = pages_df[['category']].drop_duplicates().copy()\n",
    "        subcategories_df = pages_df[['subcategory']].drop_duplicates().copy()\n",
    "\n",
    "        n_pages = pages_df.shape[0]\n",
    "        print( \"Updating pages table: Collecting text for {} articles\".format(n_pages) )\n",
    "        ## Update pages table\n",
    "        results = pages_df.apply( lambda x: db.update_page_table( x.pageid, x.title), axis = 1)\n",
    "        #results = pages_df.apply( lambda x: db.update_page_table( x.pageid, x.title, x.text), axis = 1)\n",
    "\n",
    "        print( \"Updating categories table\")\n",
    "        ## Update categories table\n",
    "        #results = categories_df.apply( lambda x: db.update_category_table( x.category), axis = 1)\n",
    "        db.update_category_table( cat)\n",
    "\n",
    "        print(\"Updating subcategories table\")\n",
    "        results = subcategories_df.apply( lambda x: db.update_sub_category_table( x.subcategory, cat), axis = 1) \n",
    "        #results = subcategories_df.apply( lambda x: db.update_sub_category_table( x.subcategory, category), axis = 1) \n",
    "\n",
    "        print(\"Updating page-category (link) table\")\n",
    "        results = pages_df.apply( lambda x: db.update_page_category_table( x.pageid, x.subcategory), axis = 1)\n",
    "        \n",
    "        timeduration = datetime.now()-start\n",
    "        \n",
    "        print(\"Article colletion for Category: {} took a total of {} minutes.\".format( cat, timeduration) )\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = English()\n",
    "page_content = wikipedia.WikipediaPage(pageid = 43385931 ).content\n",
    "page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = re.sub('\\.+', ' ', page_content)\n",
    "page_content = re.sub('[^a-z0-9 ]',' ', page_content.lower())\n",
    "page_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = re.sub('\\s+',' ',page_content)\n",
    "page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in nlp( page_content):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = ' '.join(i.orth_ for i in nlp(page_content)\n",
    "                    if i.orth_ not in STOP_WORDS)\n",
    "page_content = ' '.join(page_content.split())\n",
    "\n",
    "len(page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_content = grab_content( 43385931)\n",
    "len( test_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grab_content(43385931 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_category_pages_df, bs_unique_pages_df = fill_pages('business software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_category_pages_df.shape, bs_unique_pages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_pages('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df['text'] = pages_df.pageid.apply( grab_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_df = pd.concat( ml_category_dict.values() )\n",
    "\n",
    "ml_df.drop('ns', axis = 1, inplace = True)\n",
    "ml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_df.reset_index( drop = True, inplace = True)\n",
    "\n",
    "ml_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pages_df = ml_df.drop_duplicates(subset = ['pageid', 'title']).copy()\n",
    "\n",
    "unique_pages_df.reset_index( drop = True, inplace = True)\n",
    "\n",
    "unique_pages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_pages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_category_dict = get_pages('business software', depth = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_category_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'Free healthcare software' in bs_category_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs_category_dict[ 'business software'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len( category_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame.from_dict( category_dict)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "category_df = request_elements( category, 'subcat')\n",
    "\n",
    "category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_pages_df = request_elements( category, 'page', category)\n",
    "category_pages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = ('page', 'subcat')\n",
    "len( test)\n",
    "\n",
    "p1, p2 = test\n",
    "\n",
    "print( (*test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tester(*ptype ):\n",
    "    print( len(ptype))\n",
    "    if len( ptype) < 2:\n",
    "        print('success ' + str( len( (*ptype) )) )\n",
    "    else:\n",
    "        p1, p2 = ptype\n",
    "        #print(len(ptype))\n",
    "        \n",
    "        print( p1, p2)\n",
    "        \n",
    "        #pid1, pid2 = ptype_dict[p1], ptype_dict[p2]\n",
    "        \n",
    "        #ns_tag = pid1 + \"|\" + pid2\n",
    "    \n",
    "    #base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    #action_tag = \"?action=query&list=categorymembers&cmlimit=max\" ## fetch all category members (pages, subcategories)\n",
    "    #category_tag = '&cmtitle=Category:{}&cmtype={}&cmnamespace={}&format=json'.format( categoryF, ptype, ns_tag) ## append category to cat_tag\n",
    "    #query = base_url + action_tag + category_tag# + parameters_tag ## concatenate base_url with request tags\n",
    "    #return query    \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "query = tester( 'page', 'subcat'  ) # ('page', 'subcat' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r = requests.get( query)  ## request HTTP results\n",
    "response = r.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "format_query( 'machine learning', 'page', 'subcat', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_elements( 'machine learning', 'page', 'subcat', tag = 'machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Original\n",
    "\n",
    "def get_subcategories( category, depth =4, subcategories = []):  ## Restrixt depth to level 4\n",
    "    \n",
    "    category_df = request_elements( category, 'subcat')\n",
    "    for subcat in category_df.title.str.replace('Category:', '').tolist():\n",
    "        \n",
    "        if subcat not in subcategories:\n",
    "            subcategories.append( subcat)\n",
    "            try:\n",
    "                if depth < 0:\n",
    "                    break\n",
    "                else:\n",
    "                    subcategories = get_subcategories( subcat,depth - 1, subcategories)\n",
    "            except:\n",
    "                continue\n",
    "    return subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_df.title.str.replace('Category:', '').to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dict = {'':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict[''].append([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dict[''].append([4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    #category_df = request_elements( category, 'subcat')\n",
    "    #category_pages_df = request_elements( category, 'page', category)\n",
    "    \n",
    "    #cat_mask = category_pages\n",
    "    \n",
    "    #category_dict = {'parent':category, 'children':{}, 'articles':[]}\n",
    "    #category_dict['articles'].append( category_pages_df)\n",
    "    \n",
    "    #category_df_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\t'*0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "request_elements( 'machine learning', 'page', 'subcat', tag = 'machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tabulate = lambda x, mod: '\\t'*((3-x) + mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabulate(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "super_category = 'machine learning'\n",
    "def get_subcategories( category,depth=3, category_dict= {}  ):  ## Restrixt depth to level 4\n",
    "    category_pages_df = request_elements( category, 'page', 'subcat', tag = category)\n",
    "    #category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "    #category_dict = { category:[]}\n",
    "    pages_df_list = []\n",
    "    \n",
    "    #category_pages_df_list.append( category_pages_df)\n",
    "    \n",
    "    \n",
    "    if category_pages_df.empty:  ## if category page is empty return empty dictionary   \n",
    "        tabs = tabulate(depth, 2)\n",
    "        print( tabs + 'Empty Category')\n",
    "        return category_dict\n",
    "    else:  # otherwise, lets get separate the articles and sub-categories\n",
    "        tabs = tabulate(depth, 1)\n",
    "        #category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "\n",
    "        cat_mask = category_pages_df.title.str.contains( 'Category:')\n",
    "        \n",
    "        pages_df = category_pages_df[~cat_mask]#.copy()  ## Articles listed under category\n",
    "        #category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "        \n",
    "        print( tabs + 'New category: {} added to category_dict'.format(category) )\n",
    "        \n",
    "        #print([ cat for cat in category_dict[category]] )\n",
    "        category_df = category_pages_df[ cat_mask]#.copy()\n",
    "        \n",
    "        if category_df.empty:   ## IF no sub-categories, store the pages_df and move on\n",
    "            category_dict[category] = []\n",
    "            category_dict[category] = pages_df  ## append pages_df to category_dict list for category\n",
    "            \n",
    "            tabs = tabulate(depth, 3)\n",
    "            print( tabs + '{} has NO SUBCATEGORIES'.format( category))\n",
    "            #break\n",
    "            return category_dict\n",
    "        else:  ## Map sub-categories to a list\n",
    "            tabs = tabulate(depth, 1)\n",
    "            print( tabs +'INNER- THERE ARE SUBCATEGORIES')\n",
    "            category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "            category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "            sub_categories = category_df.title.str.replace( 'Category:', '').tolist()  \n",
    "            #print( tabs + '{}'.format(sub_categories) )\n",
    "            ## iterate through subcategories, add pages in subcategories to category pages_df list\n",
    "            \n",
    "            for i, subcat in enumerate(sub_categories[0:5]):  \n",
    "                #category_dict[ subcat] = []\n",
    "                tabs = tabulate(depth, 2)\n",
    "                #try:\n",
    "                if depth < 0:\n",
    "                    break\n",
    "                else:\n",
    "                    print( tabs + subcat + ': RECURSIVE CALL at a depth of ' + str(depth) )\n",
    "                    #category_dict[subcat] = []  ## Initialize the key-pair with an empty list\n",
    "                    category_dict[subcat] = get_subcategories( subcat, depth - 1, category_dict) #, category_dict = category_dict\n",
    "                    \n",
    "                    ## After recursive call, append the pages_df returned by the sub-category to the category- pages_df\n",
    "                    #if category_dict[subcat]: \n",
    "                    #if depth \n",
    "                    #try:\n",
    "                        #for child in category_dict[subcat]: ## original\n",
    "                    #    for child in category_dict[subcat]:\n",
    "                            \n",
    "                    #        category_dict[super_category].append( category_dict[subcat])\n",
    "                    #        category_dict[category].append( category_dict[subcat][child])  \n",
    "                    #        print( tabs + 'Adding pages from {} to super-category (children of {})'.format(child, subcat))\n",
    "                    #category_dict['articles'].append( )\n",
    "                    #except:\n",
    "                    #else:\n",
    "                    #    print( tabs + 'No pages to add to super-category from {}: '.format( subcat))\n",
    "                    #    continue\n",
    "            \n",
    "    \n",
    "            return category_dict\n",
    "                        #sub_category_dict = get_subcategories( subcat, depth -1, first_run = False) #, visited = visited                    \n",
    "\n",
    "\n",
    "                        #category_dict[subcat][]\n",
    "                        #category_dict[subcat] = {'parent': category, 'children':sub_category_dict, 'page_info':category_pages  }\n",
    "                        #category_dict[subcat] = \n",
    "                #except:\n",
    "                #    continue\n",
    "\n",
    "            #if depth == 3:    \n",
    "            #    return {category: category_dict}, \n",
    "            #else:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict = get_subcategories( 'machine learning', category_dict = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cleaned\n",
    "\n",
    "super_category = 'machine learning'\n",
    "def get_subcategories( category,depth=3, category_dict= {}  ):  ## Restrixt depth to level 4\n",
    "    category_pages_df = request_elements( category, 'page', 'subcat', tag = category)\n",
    "    \n",
    "    pages_df_list = []\n",
    "    \n",
    "    if category_pages_df.empty:  ## if category page is empty return empty dictionary   \n",
    "        tabs = tabulate(depth, 2)\n",
    "        print( tabs + 'Empty Category')\n",
    "        #category_dict[ category] = []\n",
    "        return category_dict\n",
    "    else:  # otherwise, lets get separate the articles and sub-categories\n",
    "        tabs = tabulate(depth, 1)\n",
    "    \n",
    "        cat_mask = category_pages_df.title.str.contains( 'Category:')\n",
    "        category_df = category_pages_df[ cat_mask].copy()\n",
    "       \n",
    "        pages_df = category_pages_df[~cat_mask].copy()  ## Articles listed under category\n",
    "        \n",
    "        print( tabs + 'New category: {} added to category_dict'.format(category) )\n",
    "        \n",
    "        \n",
    "        \n",
    "        if category_df.empty:   ## IF no sub-categories, store the pages_df and move on\n",
    "            #category_dict[category] = []\n",
    "            category_dict[category] = pages_df  ## append pages_df to category_dict list for category\n",
    "            \n",
    "            tabs = tabulate(depth, 3)\n",
    "            print( tabs + '{} has NO SUBCATEGORIES'.format( category))\n",
    "           \n",
    "            return category_dict #[category]\n",
    "        else:  ## Map sub-categories to a list\n",
    "            tabs = tabulate(depth, 1)\n",
    "            print( tabs +'INNER- THERE ARE SUBCATEGORIES')\n",
    "            ##NEW\n",
    "            category_dict[category] = []\n",
    "            category_dict[category].append(pages_df)\n",
    "            ##ONLY THIScategory_dict[category] = pages_df  ## append pages_df to category_dict list for category\n",
    "            sub_categories = category_df.title.str.replace( 'Category:', '').tolist()  \n",
    "            ## iterate through subcategories, add pages in subcategories to category pages_df list\n",
    "            \n",
    "            for i, subcat in enumerate(sub_categories[0:3]):  \n",
    "                #category_dict[ subcat] = []\n",
    "                tabs = tabulate(depth, 2)\n",
    "                #try:\n",
    "                if depth < 0:\n",
    "                    break\n",
    "                else:\n",
    "                    print( tabs + subcat + ': RECURSIVE CALL at a depth of ' + str(depth) )\n",
    "                    category_dict = get_subcategories( subcat, depth - 1)\n",
    "                    ## NEW\n",
    "                    if type( category_dict[subcat]) is list:\n",
    "                        pages_df_from_category = pd.concat( category_dict[subcat] )\n",
    "                        category_dict[category].append(pages_df_from_category  )\n",
    "                    else:\n",
    "                        category_dict[category].append( category_dict[subcat] )\n",
    "                    \n",
    "                                        \n",
    "                    #category_dict[category].append( category_dict[subcat] )\n",
    "            ## NEW NEW\n",
    "            category_dict[category] = pd.concat( category_dict[category])  \n",
    "\n",
    "            \n",
    "            \n",
    "            return category_dict\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = get_subcategories('machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_dict['machine learning']), len(cat_dict['Applied machine learning']), len(cat_dict['Artificial neural networks'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict['Artificial neural networks']  ## machine learning , Applied machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cat_dict['machine learning'][2]\n",
    "if type(test) is list:\n",
    "    print( 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([key for key in cat_dict['Deep learning'] ]) ## Artificial neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cat_dict['Artificial neural networks']), len(cat_dict['machine learning'])  ## , len(category_dict['Deep learning'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category\n",
    "category_pages_df = request_elements( category, 'page', 'subcat', tag = category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_pages_df = request_elements( category, 'page', 'subcat', tag = category)\n",
    "    #category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "    #category_dict = { category:[]}\n",
    "    \n",
    "    pages_df_list = []\n",
    "    \n",
    "    #category_pages_df_list.append( category_pages_df)\n",
    "    \n",
    "    \n",
    "    if category_pages_df.empty:  ## if category page is empty return empty dictionary   \n",
    "        tabs = tabulate(depth, 2)\n",
    "        print( tabs + 'Empty Category')\n",
    "        return category_dict\n",
    "    else:  # otherwise, lets get separate the articles and sub-categories\n",
    "        tabs = tabulate(depth, 1)\n",
    "        category_dict[category] = []  ## Initialize the key-pair with an empty list\n",
    "\n",
    "        cat_mask = category_pages_df.title.str.contains( 'Category:')\n",
    "        \n",
    "        pages_df = category_pages_df[~cat_mask]#.copy()  ## Articles listed under category\n",
    "        #category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "        \n",
    "        print( tabs + 'New category: {} added to category_dict'.format(category) )\n",
    "        \n",
    "        #print([ cat for cat in category_dict[category]] )\n",
    "        category_df = category_pages_df[ cat_mask]#.copy()\n",
    "        \n",
    "        if category_df.empty:   ## IF no sub-categories, store the pages_df and move on\n",
    "            category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "            tabs = tabulate(depth, 3)\n",
    "            print( tabs + '{} has NO SUBCATEGORIES'.format( category))\n",
    "            #break\n",
    "            return category_dict\n",
    "        else:  ## Map sub-categories to a list\n",
    "            tabs = tabulate(depth, 1)\n",
    "            print( tabs +'INNER- THERE ARE SUBCATEGORIES')\n",
    "            category_dict[category].append( pages_df)  ## append pages_df to category_dict list for category\n",
    "            sub_categories = category_df.title.str.replace( 'Category:', '').tolist()  \n",
    "            #print( tabs + '{}'.format(sub_categories) )\n",
    "            ## iterate through subcategories, add pages in subcategories to category pages_df list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cat in category_dict['Artificial neural networks']:\n",
    "    print(cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in category_dict['Classification algorithms']:\n",
    "    print( cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in category_dict['Deep learning']:\n",
    "    print( cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dict['Artificial neural networks'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## new attempt\n",
    "\n",
    "def get_pages( category, depth = 4, first_run = True):\n",
    "    \n",
    "    \n",
    "    category_df = request_elements( category, 'subcat')\n",
    "    \n",
    "    catdict = {}\n",
    "    pages_df_list = []\n",
    "    \n",
    "    if category_df.empty:\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## THIS WORKS\n",
    "\n",
    "def get_subcategories1( category, depth =4, first_run = True): #, visited = []):  ## Restrixt depth to level 4\n",
    "    \n",
    "    category_df = request_elements( category, 'subcat')\n",
    "    \n",
    "    category_pages_df = request_elements( category, 'page', category)\n",
    "    \n",
    "    #subcats = [cat for cat in category_df.title.str.replace('Category:', '').tolist() if cat not in visited]\n",
    "    \n",
    "    #print( subcats)\n",
    "    \n",
    "    #visited += subcats\n",
    "    \n",
    "    catdict = {}\n",
    "    \n",
    "    pages_df_list = []\n",
    "    \n",
    "    if category_df.empty:\n",
    "        return catdict\n",
    "    else:\n",
    "        subcats = [cat for cat in category_df.title.str.replace('Category:', '').tolist()] # if cat not in visited]\n",
    "    #catdict[category] =  subcats\n",
    "    \n",
    "    #cat_labels = category + \"/\"\n",
    "    \n",
    "    for subcat in subcats:\n",
    "        try:\n",
    "            if depth < 0:\n",
    "                break\n",
    "            else:\n",
    "                catdict[subcat] = get_subcategories1( subcat, depth -1, first_run = False) #, visited = visited)\n",
    "                #subcatdict = catdict[category][subcat]\n",
    "            #try:\n",
    "            #    if depth < 0:\n",
    "            #        #print(\"BREAK\")\n",
    "            #        break\n",
    "            #    else:\n",
    "            #        subcategories, catdict = get_subcategories( subcat,depth - 1, subcategories, subcatdict)\n",
    "        except:\n",
    "            continue\n",
    "    if first_run:\n",
    "        return {category: catdict}\n",
    "    else:\n",
    "        return catdict\n",
    "    #return catdict\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
