{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import request_category as rc\n",
    "import database as db\n",
    "from download import download\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT crap_ml.category, crap_ml.subcategory, p.pageid, p.title, p.article FROM (SELECT stuff.category, stuff.subcategory, pc.pageid FROM ( SELECT category, subcategory, subcategory_id FROM subcategories sc JOIN categories c ON sc.category_id = c.category_id WHERE category ='machine learning' ) as stuff JOIN page_category pc ON stuff.subcategory_id = pc.subcategory_id ) as crap_ml JOIN pages p ON crap_ml.pageid = p.pageid \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Machine learning - Grab all the unique articles with title and pageid\n",
    "\n",
    "inner_ml = \"\"\"SELECT stuff.category, stuff.subcategory, pc.pageid \n",
    "              FROM ( SELECT category, subcategory, subcategory_id \n",
    "                     FROM subcategories sc \n",
    "                         JOIN categories c \n",
    "                         ON sc.category_id = c.category_id \n",
    "                     WHERE category ='machine learning' ) as stuff \n",
    "              JOIN page_category pc \n",
    "              ON stuff.subcategory_id = pc.subcategory_id             \n",
    "              \"\"\"  #               HAVING COUNT(pc.pageid) = 1 ,        \n",
    "\n",
    "ml_pages_query = \"\"\"SELECT crap_ml.category, crap_ml.subcategory, p.pageid, p.title, p.article\n",
    "                    FROM ({}) as crap_ml\n",
    "                    JOIN pages p\n",
    "                    ON crap_ml.pageid = p.pageid\n",
    "                    \n",
    "                \"\"\".format( inner_ml) # LIMIT 1000  ## GROUP BY crap_ml.category, crap_ml.subcategory, p.pageid\n",
    "                    #HAVING COUNT( crap_ml.pageid) = 1, DISTINCT,  crap_ml.subcategory,\n",
    "ml_pages_query = re.sub( \"\\s+\",\" \", ml_pages_query)\n",
    "ml_pages_query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SELECT crap_bs.category, crap_bs.subcategory, p.pageid, p.title, p.article FROM (SELECT stuff.category, stuff.subcategory, pc.pageid FROM ( SELECT category, subcategory, subcategory_id FROM subcategories sc JOIN categories c ON sc.category_id = c.category_id WHERE category ='business software' ) as stuff JOIN page_category pc ON stuff.subcategory_id = pc.subcategory_id ) as crap_bs JOIN pages p ON crap_bs.pageid = p.pageid \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Business Software - Grab all the unique articles with title and pageid\n",
    "#inner_bs = db.category_query( ('\\'business software\\''))\n",
    "inner_bs = \"\"\"SELECT stuff.category, stuff.subcategory, pc.pageid \n",
    "                        FROM ( SELECT category, subcategory, subcategory_id \n",
    "                               FROM subcategories sc \n",
    "                                   JOIN categories c \n",
    "                                   ON sc.category_id = c.category_id \n",
    "                               WHERE category ='business software' ) as stuff \n",
    "                        JOIN page_category pc \n",
    "                        ON stuff.subcategory_id = pc.subcategory_id\n",
    "                        \"\"\"   #  GROUP BY stuff.category, stuff.subcategory, pc.pageid\n",
    "\n",
    "bs_pages_query = \"\"\"SELECT crap_bs.category, crap_bs.subcategory, p.pageid, p.title, p.article\n",
    "                    FROM ({}) as crap_bs\n",
    "                    JOIN pages p\n",
    "                    ON crap_bs.pageid = p.pageid\n",
    "                    \n",
    "                 \"\"\".format(inner_bs)  ## DISTINCT, LIMIT 1000, HAVING COUNT(crap_bs.pageid) = 1, crap_bs.category, crap_bs.subcategory,\n",
    "bs_pages_query = re.sub( \"\\s+\",\" \", bs_pages_query)\n",
    "bs_pages_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2768, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_query = \"\"\"SELECT b.category, b.subcategory, b.title, b.pageid, b.article\n",
    "                 FROM (({}) UNION ({}) ) as b;\"\"\".format( ml_pages_query, bs_pages_query)\n",
    "\n",
    "pages_df = db.query_to_dataframe( pages_query)\n",
    "pages_df.shape  # shape = (2425, 3) Before adding category and subcategory\n",
    "                ## shape = (2768, 3) after adding Distinct category and subcategory in outer query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from search import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2756, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_df = get_data('machine learning', 'business software')\n",
    "pages_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "pages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print( 'Total titles: {}'.format(pages_df.drop( ['pageid'], axis = 1).groupby( by = ['category', 'subcategory']).count().sum() ) )\n",
    "pages_df.drop( ['pageid'], axis = 1).groupby( by = ['category', 'subcategory']).count()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df[ pages_df.pageid == 26137900]  # 11273721"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pages_df.drop_duplicates( subset = ['category', 'pageid','title'], keep='last').copy()  ## 'category', "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duplicates_df = test[( test.pageid == 12185719) | (test.pageid == 41732818 ) | ( test.pageid == 462546) | (test.pageid == 36089423)]  # 11273721\n",
    "\n",
    "duplicates_df.drop( ['pageid'], axis = 1).groupby( by = ['category', 'subcategory']).count()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print( 'Total titles: {}'.format(pages_df.drop( ['pageid'], axis = 1).groupby( by = ['category', 'subcategory']).count().sum() ) )\n",
    "#pages_df.drop( ['pageid'], axis = 1).groupby( by = ['category', 'subcategory']).count()\n",
    "\n",
    "test.drop( ['pageid'], axis = 1).groupby( by = ['category', 'subcategory']).count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df.pageid == value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "test.pageid.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As is, no removal of duplicates\n",
    "\n",
    "## MNLogistic,  Build classifier for ML or BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.externals.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pages_df['article'].copy()\n",
    "#pages_df[['category']]\n",
    "\n",
    "#X.index = X.pageid\n",
    "#X.drop(['pageid'], axis = 1, inplace = True)\n",
    "\n",
    "#Y = pages_df[['category', 'subcategory']].copy()\n",
    "\n",
    "#lb = LabelBinarizer()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y = encoder.fit_transform( pages_df['category'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1584    encog machine learning framework available jav...\n",
       "1800    ibm current microsoft windows based graphical ...\n",
       "2429    mtconnect manufacturing technical standard ret...\n",
       "1706    quake markup language quakeml flexible extensi...\n",
       "1027    micai short mexican international conference a...\n",
       "240     spider project project management software dev...\n",
       "1032    fasttrack schedule project management software...\n",
       "582     waffles collection command line tools performi...\n",
       "1792    highdeal privately owned bss software product ...\n",
       "862     procurify cloud based procurement software com...\n",
       "1681    webengage privately held saas company based mu...\n",
       "1435    xgboost open source software library provides ...\n",
       "350     statistical learning theory representer theore...\n",
       "2537    balanced scorecard bsc strategy performance ma...\n",
       "1058    deeplearningj deep learning programming librar...\n",
       "1966    geoffrey everest hinton frs born december brit...\n",
       "1491    easynote web based project management tool cre...\n",
       "1547    solveit software pty ltd provider advanced pla...\n",
       "789     turi graph based high performance distributed ...\n",
       "1860    manufacturing execution systems mes computeriz...\n",
       "964     structured k nearest neighbours machine learni...\n",
       "657     united medical information analytical system m...\n",
       "2622    primavera enterprise project portfolio managem...\n",
       "1001    java naming directory interface jndi java api ...\n",
       "1896    pipeline pilot authoring tool accelrys enterpr...\n",
       "2483    following list notable report generator softwa...\n",
       "1973    bag oob error called bag estimate method measu...\n",
       "2112    hierarchical temporal memory htm biologically ...\n",
       "1511    cdc marketfirst business software product use ...\n",
       "841     infomax optimization principle artificial neur...\n",
       "                              ...                        \n",
       "975     game dev tycoon business simulation video game...\n",
       "2047    mathematics bondy s theorem bound number eleme...\n",
       "2558    variational message passing vmp approximate in...\n",
       "1082    casecomplete requirements management applicati...\n",
       "474     linear discriminant analysis lda generalizatio...\n",
       "747     priority matrix time management software appli...\n",
       "2300    areas information science finding predictive r...\n",
       "21      opennn open neural networks library software l...\n",
       "459     space bucks space trading simulation developed...\n",
       "1184    alpha capture system computer system enables i...\n",
       "2324    visual compliance known ecustoms technology co...\n",
       "955     hypercube based neat hyperneat generative enco...\n",
       "1215    team foundation server commonly abbreviated tf...\n",
       "2433    project team builder abbreviated ptb project m...\n",
       "1515    contributors needed write definitions terms gl...\n",
       "2391    computational learning theory mathematics give...\n",
       "769     neural networks monthly peer reviewed scientif...\n",
       "1685    netsuite american cloud computing company base...\n",
       "130     machine learning hyper basis function network ...\n",
       "2135    factored language model flm extension conventi...\n",
       "1482    intraboom software service saas company based ...\n",
       "330     construction collaboration technology refers s...\n",
       "1238    vigra abbreviation vision generic algorithms f...\n",
       "466     computational networks activation function nod...\n",
       "2169    productivity software called personal producti...\n",
       "1638    machine learning statistics classification pro...\n",
       "1095    ats automation tooling systems cambridge ontar...\n",
       "1130    meniga software company founded reykjavik icel...\n",
       "1294    aiai administrative interactive assistance int...\n",
       "860     liferay portal free open source enterprise por...\n",
       "Name: article, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer( ngram_range = (1,2),\n",
    "                             min_df = 3, max_df = .9, \n",
    "                             stop_words = 'english')\n",
    "                             \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sps = vectorizer.fit_transform( X_train) # X_train['article']\n",
    "\n",
    "X_test_sps = vectorizer.transform( X_test)\n",
    "\n",
    "train_prior_df = pd.DataFrame(  X_train_sps.toarray(), \n",
    "                     columns = vectorizer.get_feature_names())\n",
    "\n",
    "\n",
    "test_prior_df = pd.DataFrame( X_test_sps.toarray(),\n",
    "                            columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train#.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_prior_df.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n",
    "\n",
    "import sklearn.externals.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_components = 700\n",
    "SVD = TruncatedSVD(n_components)\n",
    "component_names = [\"component_\"+str(i+1) for i in range(n_components)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2076, 700)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## dtm\n",
    "train_svd_matrix = SVD.fit_transform( train_prior_df)\n",
    "\n",
    "test_svd_matrix = SVD.transform( test_prior_df)\n",
    "train_svd_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_latent_semantic_analysis = pd.DataFrame(train_svd_matrix,\n",
    "                                        index=train_prior_df.index,#nonempty_pages_df.pageid,\n",
    "                                        columns=component_names)\n",
    "\n",
    "test_latent_semantic_analysis = pd.DataFrame(test_svd_matrix,\n",
    "                                        index=test_prior_df.index,#nonempty_pages_df.pageid,\n",
    "                                        columns=component_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latent_semantic_analysis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.19645436, -0.00302654,  0.10013735, ..., -0.00348833,\n",
       "         0.01514014,  0.01272561],\n",
       "       [ 0.16481159, -0.15997568, -0.0382075 , ...,  0.0223714 ,\n",
       "        -0.01490773, -0.00627058],\n",
       "       [ 0.19434109, -0.14735876, -0.00815371, ...,  0.04600086,\n",
       "        -0.00994328, -0.00448326],\n",
       "       ..., \n",
       "       [ 0.09754335, -0.11228189, -0.01451931, ...,  0.0201884 ,\n",
       "        -0.0216765 ,  0.02384504],\n",
       "       [ 0.055216  , -0.06603691, -0.01101332, ..., -0.01660244,\n",
       "        -0.00866171,  0.01749349],\n",
       "       [ 0.09149554, -0.11063171, -0.04679369, ..., -0.03525711,\n",
       "         0.03197779, -0.03531844]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit_transform( train_latent_semantic_analysis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97880539499036612"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score( train_latent_semantic_analysis, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95809248554913296"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.score( test_latent_semantic_analysis, y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_text     = vectorizer.fit_transform(df['text'])\n",
    "prior      = pd.DataFrame(\n",
    "    X_text.toarray(), \n",
    "    columns=vectorizer.get_feature_names()\n",
    ")\n",
    "\n",
    "prior.index = df['label']\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pages_df[['article']].copy()\n",
    "pages_df[['category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## As is, no removal of duplicates\n",
    "\n",
    "## MNLogistic,  Build classifier for ML or BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pages_df['article'].copy()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform( pages_df['category'] )\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e-03,   1.00000000e-02,   1.00000000e-01,\n",
       "         1.00000000e+00,   1.00000000e+01,   1.00000000e+02,\n",
       "         1.00000000e+03])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-3,3,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97495183044315992"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('encoder', TfidfVectorizer(ngram_range = (1,2),\n",
    "                             min_df = 3, max_df = .9, \n",
    "                             stop_words = 'english')),\n",
    "    ('truncator',TruncatedSVD(n_components=700) ),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "lr_params = {\n",
    "    'model__C':[1,10]  #np.logspace(-3,3,7)\n",
    "}\n",
    "\n",
    "gs_lr_pipe = GridSearchCV(lr_pipe, param_grid=lr_params, cv=5) # StratifiedShuffleSplit(n_splits=5)\n",
    "\n",
    "gs_lr_pipe.fit(X_train,y_train)\n",
    "\n",
    "gs_lr_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.externals.joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./LogitModel1.p']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.externals.joblib.dump(gs_lr_pipe, './LogitModel1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gssklearn.externals.joblib.load('./LogitModel1.p')\n",
    "#dump(gs_lr_pipe, './LogitModel1.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99470134874759153"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_pipe.score( X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97109826589595372"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_pipe.score( X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_json( search_term, query):\n",
    "    r = requests.get( query)  ## request HTTP results\n",
    "    response = r.json()\n",
    "    pageinfo = response['query']['pages']\n",
    "    if isinstance( search_term, str):\n",
    "        \n",
    "        pageid = list(pageinfo.keys())[0]\n",
    "        text = pageinfo[pageid]['extract']\n",
    "    elif isinstance( search_term, int):\n",
    "        pageid = str(search_term)\n",
    "        text = pageinfo[pageid]['extract']\n",
    "        \n",
    "    return text, pageid\n",
    "    \n",
    "\n",
    "def get_article( search_term ):# title or page id, Capitalization ignored\n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    if isinstance( search_term, str):\n",
    "        #search_term = rc.format_search( search_term)\n",
    "        tag = 'titles={}'.format( search_term)\n",
    "    elif isinstance( search_term, int):\n",
    "        tag = 'pageids={}'.format( search_term)\n",
    "    else:\n",
    "        print( 'Invalid search term...')\n",
    "        return ''\n",
    "\n",
    "    action_tag = \"?action=query&prop=extracts&explaintext&{}&format=json\".format( tag) \n",
    "    query = base_url + action_tag\n",
    "    \n",
    "    article_text, pageid = get_json( search_term, query)\n",
    "    \n",
    "    return article_text, pageid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://en.wikipedia.org/w/api.php?action=query&prop=extracts&explaintext&titles=Saffron Technology&format=json'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_text, pageid = get_article( 'Saffron Technology')\n",
    "article_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brain organ serves center nervous system vertebrate invertebrate animals brain located head usually close sensory organs senses vision brain complex organ vertebrate s body human cerebral cortex conta'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_doc, pageid = rc.get_article('Brain')  # Saffron Technology\n",
    "search_doc = rc.cleaner( search_doc)\n",
    "##print( pageid )\n",
    "search_doc[0:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/deprecation.py:70: DeprecationWarning: Function transform is deprecated; Support to use estimators as feature selectors will be removed in version 0.19. Use SelectFromModel instead.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  1.35170158e-01,  -3.80362820e-02,   5.87758322e-02,\n",
       "          1.26285511e-01,  -2.40289597e-02,   1.81071763e-02,\n",
       "          6.01996672e-02,   4.52544696e-02,  -3.72924130e-02,\n",
       "          5.53361822e-03,   1.13731421e-03,   2.89964043e-02,\n",
       "          2.26841906e-02,   1.79729990e-03,   1.33493254e-02,\n",
       "          3.46916703e-03,  -1.38465959e-02,  -3.70860993e-03,\n",
       "         -2.09624619e-02,  -3.69160943e-03,   5.82900874e-03,\n",
       "          1.29680398e-02,  -2.58796948e-02,   1.32402450e-02,\n",
       "          7.90851768e-02,   8.71380932e-03,  -1.85801961e-02,\n",
       "          2.00458108e-02,  -1.88684068e-02,   3.19256858e-02,\n",
       "          1.36056457e-02,   3.26715774e-02,   3.39892612e-05,\n",
       "          4.75276091e-04,   3.92622375e-02,   2.36597557e-02,\n",
       "          1.72693944e-02,  -2.54538977e-02,   2.81257282e-02,\n",
       "          1.65605267e-02,  -1.57573774e-02,  -1.93420508e-02,\n",
       "         -1.07358920e-02,  -3.39645447e-02,  -2.55434794e-02,\n",
       "          6.01422475e-03,  -2.53142937e-02,   7.97866670e-02,\n",
       "         -1.15707008e-02,  -8.24036703e-03,   4.20836676e-02,\n",
       "         -3.08674272e-02,   2.83191411e-02,  -1.39613349e-02,\n",
       "          3.28719089e-02,  -1.82085911e-02,   1.77670399e-02,\n",
       "         -1.29677014e-03,  -3.43626537e-02,   8.92433940e-03,\n",
       "          2.16734204e-02,  -5.92793508e-03,  -4.61228684e-03,\n",
       "          3.71503176e-02,   3.61485615e-02,   1.23368133e-02,\n",
       "          2.78239805e-03,  -4.88493760e-02,   4.82100099e-03,\n",
       "          3.09567526e-02,   3.05675841e-03,   1.37675558e-02,\n",
       "          8.09291467e-02,  -3.74771081e-02,   2.72587599e-02,\n",
       "         -1.26597753e-02,   8.14412898e-03,   4.47877982e-03,\n",
       "         -2.61643685e-02,  -2.87974794e-02,   2.21194700e-02,\n",
       "         -4.53400983e-03,   5.39455802e-02,   2.37906681e-02,\n",
       "         -1.07883870e-02,   2.07873825e-02,   3.43053836e-05,\n",
       "         -1.17515745e-03,  -2.15372672e-02,  -2.11056587e-02,\n",
       "         -2.11454087e-02,  -1.24171845e-02,   1.07282554e-02,\n",
       "         -2.60248424e-02,  -5.27756156e-02,   1.93878495e-03,\n",
       "          1.54405210e-03,  -7.29925374e-03,   9.60749936e-03,\n",
       "          2.17667540e-02,  -1.83882706e-02,  -2.46879344e-02,\n",
       "          7.37758742e-03,   1.20166366e-02,   1.81403614e-02,\n",
       "          6.04412606e-03,  -1.08446764e-02,   2.88603067e-03,\n",
       "          3.02028531e-02,  -8.04940758e-03,   3.20577790e-03,\n",
       "         -7.17471053e-03,  -2.70153152e-03,  -6.59241119e-03,\n",
       "          4.16473800e-03,  -7.69634884e-03,   1.10758747e-02,\n",
       "          1.71207745e-02,   9.88308991e-03,   9.11757878e-03,\n",
       "         -1.55501676e-02,  -1.19040482e-02,  -3.07889239e-03,\n",
       "          2.60614827e-02,  -2.81367161e-03,   1.83065362e-02,\n",
       "         -2.23406867e-02,   1.09103584e-02,   1.23881679e-02,\n",
       "         -1.80970007e-02,  -1.03930787e-02,  -1.78172586e-02,\n",
       "         -2.28621213e-03,  -1.50520285e-02,   2.13165993e-03,\n",
       "          8.53613562e-03,  -1.49705191e-02,   2.07301685e-02,\n",
       "          1.33073035e-02,  -2.34312107e-02,  -6.26019289e-03,\n",
       "         -5.00120957e-03,  -1.19574925e-03,   1.34533129e-02,\n",
       "         -1.45331919e-02,   9.06922428e-03,  -1.36405731e-02,\n",
       "          2.78778664e-03,  -5.01937415e-03,   1.90547577e-02,\n",
       "         -8.27840559e-03,  -2.27680675e-02,   1.08896567e-02,\n",
       "          1.34653041e-02,  -4.68558375e-03,  -5.87165202e-04,\n",
       "          1.42382076e-02,   3.50779528e-03,  -6.62655555e-03,\n",
       "         -2.74741997e-02,  -1.60772253e-02,  -1.50404734e-02,\n",
       "          4.53382444e-03,  -1.58439875e-02,  -1.97817269e-02,\n",
       "          9.57975876e-03,  -1.28426965e-03,  -5.47590789e-03,\n",
       "         -1.23488086e-02,  -1.48245209e-02,  -5.35933240e-03,\n",
       "          1.37803494e-02,  -5.81372489e-03,   1.14653855e-02,\n",
       "          6.85225299e-03,   3.90086603e-03,  -2.21431845e-02,\n",
       "         -1.44275652e-02,  -2.55330361e-03,  -4.41374749e-03,\n",
       "         -4.59002458e-03,   1.73449672e-03,  -7.55033575e-03,\n",
       "         -4.77383152e-03,   5.80211410e-03,   4.26270614e-03,\n",
       "         -3.54648314e-04,   1.36704045e-02,  -3.30696572e-03,\n",
       "          7.02417929e-03,   5.08832478e-03,  -7.92400527e-03,\n",
       "          6.99892154e-03,   9.39343303e-03,  -1.12547880e-02,\n",
       "         -1.73705942e-02,   3.24838147e-03,   7.22262013e-03,\n",
       "         -3.76025132e-03,   1.78619308e-03,   5.57550205e-03,\n",
       "         -6.63738173e-03,   8.63930091e-04,   2.12251597e-02,\n",
       "         -1.32859147e-02,  -1.11289667e-03,   1.27532344e-02,\n",
       "          1.46227982e-02,   2.07759352e-04,   1.75851407e-02,\n",
       "          1.99446977e-03,   4.17482409e-03,   1.75157177e-02,\n",
       "         -3.26755235e-03,   2.79553871e-03,  -3.32129322e-03,\n",
       "         -7.56771563e-04,  -2.48883463e-02,   1.75860039e-02,\n",
       "          2.74226724e-03,   1.45405650e-02,   1.52347384e-02,\n",
       "         -8.38704937e-03,   2.12690422e-03,  -1.96101019e-02]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_pipe.transform([search_doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gs_lr_pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0ae4fba60b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgs_lr_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearch_doc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m## 'Brain'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'gs_lr_pipe' is not defined"
     ]
    }
   ],
   "source": [
    "gs_lr_pipe.predict_proba([search_doc])  ## 'Brain'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99873895,  0.00126105]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_pipe.predict_proba([search_doc])  ## 'Microsoft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00227817,  0.99772183]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_pipe.predict_proba([search_doc])  ## 'Statistics'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.60603483,  0.39396517]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_lr_pipe.predict_proba([search_doc])  ## 'Saffron Technology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pages_df['article'].copy()\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform( pages_df['category'] )\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([\n",
    "    ('encoder', TfidfVectorizer(ngram_range = (1,2),\n",
    "                             min_df = 3, max_df = .9, \n",
    "                             stop_words = 'english')),\n",
    "    ('truncator',TruncatedSVD(n_components=700) ),\n",
    "    ('model', LogisticRegression())\n",
    "])\n",
    "\n",
    "lr_params = {\n",
    "    'model__C':[1,10]  #np.logspace(-3,3,7)\n",
    "}\n",
    "\n",
    "gs_lr_pipe = GridSearchCV(lr_pipe, param_grid=lr_params, cv=5) # StratifiedShuffleSplit(n_splits=5)\n",
    "\n",
    "gs_lr_pipe.fit(X_train,y_train)\n",
    "\n",
    "gs_lr_pipe.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
