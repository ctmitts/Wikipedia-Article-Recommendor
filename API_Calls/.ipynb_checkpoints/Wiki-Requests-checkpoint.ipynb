{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import wikipedia\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.mediawiki.org/wiki/API:Main_page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CRUD\n",
    "\n",
    "| | SQL | RESTful API |\n",
    "|:-:|:-:|:-:|\n",
    "| create | `INSERT` | `POST` |\n",
    "| read | `SELECT` | `GET` |\n",
    "| update | `UPDATE` | `PUT` |\n",
    "| delete | `DELETE` | `DELETE` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://interactive.blockdiag.com/image?compression=deflate&encoding=base64&src=eJxLyslPzk7JTExXqOZSUFAPcnV0UUgrys9VCM_MzixIBcqoK-jaKRSlFpfmlBSDmOrlRZklqQol-QoF-cUl6UAZdWuuWgBXuhe4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Wikipedia\n",
    "\n",
    "## API Tutorial (mediawiki API)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Get on Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "request_category( 'business software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def category_format( category):\n",
    "    category_query = re.sub( '\\s', '+', category)\n",
    "    return category_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def request_category( category ):  ##  exclude  ## Cmtype\n",
    "    \n",
    "    #category_query = category_format( category)\n",
    "    \n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    action_tag = \"?action=query&list=categorymembers&cmlimit=max\" ## fetch all category members (pages, subcategories)\n",
    "    category_tag = '&cmtitle=Category:{}'.format( category) ## append category to cat_tag\n",
    "    parameters_tag = \"&format=json&prop=info|categories|links\" ## return in json format\n",
    "    request_call = base_url + action_tag + category_tag + parameters_tag ## concatenate base_url with request tags\n",
    "\n",
    "    r = requests.get( request_call)  ## request HTTP results\n",
    "    response = r.json()\n",
    "    \n",
    "    category_pages = response['query']['categorymembers']\n",
    "    \n",
    "    \n",
    "    category_pages_df = pd.DataFrame( response['query']['categorymembers'] )\n",
    "    \n",
    "    return category_pages_df\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_pages_df = request_category( 'machine learning')\n",
    "sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "category_pages_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_pages_df[ ~sub_category_mask].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## sub-categories\n",
    "\n",
    "orig_categories = category_pages_df[ sub_category_mask].title.str.replace('Category:','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Original \n",
    "\n",
    "def gather_articles( category ):\n",
    "    '''Collect all articles that belong to a category, including articles found in sub-categories.\n",
    "        This process is performed recursively to find all relevant articles in the domain space'''\n",
    "    print(category)\n",
    "    category_pages_df = request_category( category)  ## load dataframe of pages contained in category\n",
    "    \n",
    "    sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "    \n",
    "    pages_df_list = []\n",
    "    categories_pageid_dict = {}\n",
    "    \n",
    "    pages_df = category_pages_df[ ~sub_category_mask]\n",
    "    pages_df_list.append( pages_df)\n",
    "    \n",
    "    sub_categories = category_pages_df[ sub_category_mask].title.str.replace( 'Category:', '').tolist()    ## Create list of all sub-category names ( Category: <name>), remove the preface                \n",
    "    categories_pageid_dict[ category] = pages_df.pageid\n",
    "    n_sub_categories = sum( sub_category_mask)  ## Number of sub-categories belong to category\n",
    "    \n",
    "    if n_sub_categories > 0:\n",
    "        for sub_category in sub_categories:  ## recursively, one at a time     \n",
    "            sub_category_pages = gather_articles( sub_category )[0]\n",
    "            \n",
    "            categories_pageid_dict[ sub_category] = sub_category_pages.pageid\n",
    "            \n",
    "            \n",
    "            pages_df_list.append( sub_category_pages  )\n",
    "            \n",
    "\n",
    "    pages_df = pd.concat( pages_df_list)\n",
    "    pages_df.reset_index()\n",
    "    return pages_df, categories_pageid_dict\n",
    "    \n",
    "    \n",
    "    #pages_df_list.append(  category_pages_df[~sub_category_mask].pageid.apply( grab_content ))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NEW,  Added error handling for empty category\n",
    "\n",
    "def gather_articles( category):  #  used_subcategories = [] \n",
    "    '''Collect all articles that belong to a category, including articles found in sub-categories.\n",
    "        This process is performed recursively to find all relevant articles in the domain space'''\n",
    "    \n",
    "    category_pages_df = request_category( category)  ## load dataframe of pages contained in category\n",
    "    \n",
    "    sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "\n",
    "    pages_df_list = []\n",
    "    categories_pageid_dict = {}\n",
    "\n",
    "    pages_df = category_pages_df[ ~sub_category_mask]\n",
    "    pages_df_list.append( pages_df)\n",
    "\n",
    "    sub_categories = category_pages_df[ sub_category_mask].title.str.replace( 'Category:', '').tolist()    ## Create list of all sub-category names ( Category: <name>), remove the preface                \n",
    "    categories_pageid_dict[ category] = pages_df.pageid\n",
    "    n_sub_categories = sum( sub_category_mask)  ## Number of sub-categories belong to category\n",
    "\n",
    "    if n_sub_categories > 0:\n",
    "        for sub_category in sub_categories:  ## recursively, one at a time\n",
    "            try:\n",
    "                if sub_category not in categories_pageid_dict.keys():  ## skip categories already visited\n",
    "                #try:\n",
    "                    print('New sub-category: {}'.format( sub_category) )\n",
    "                    sub_category_pages = gather_articles( sub_category )#[0]\n",
    "\n",
    "                    categories_pageid_dict[ sub_category] = sub_category_pages.pageid\n",
    "\n",
    "\n",
    "                    pages_df_list.append( sub_category_pages  )\n",
    "                #except: \n",
    "                #    print( '+++Category: {} is empty'.format(sub_category) )\n",
    "                #    continue\n",
    "                if sub_category in categories_pageid_dict.keys():\n",
    "                    print( '***Category: {} already looked at'.format( sub_category))\n",
    "                    continue\n",
    "            except: \n",
    "                print( '+++Category: {} is empty'.format(sub_category) )\n",
    "                continue\n",
    "            \n",
    "                \n",
    "\n",
    "    pages_df = pd.concat( pages_df_list)\n",
    "    #pages_df.reset_index()\n",
    "    return pages_df, categories_pageid_dict\n",
    "\n",
    "    #return 'Empty Category'\n",
    "\n",
    "\n",
    "#pages_df_list.append(  category_pages_df[~sub_category_mask].pageid.apply( grab_content ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NEW,  Added error handling for empty category\n",
    "\n",
    "def gather_articles( category, count = 1):  #  used_subcategories = [] \n",
    "    '''Collect all articles that belong to a category, including articles found in sub-categories.\n",
    "        This process is performed recursively to find all relevant articles in the domain space'''\n",
    "    \n",
    "    category_pages_df = request_category( category)  ## load dataframe of pages contained in category\n",
    "    \n",
    "    sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "\n",
    "    pages_df_list = []\n",
    "    if count == 1:\n",
    "        categories_pageid_dict = {}\n",
    "\n",
    "    pages_df = category_pages_df[ ~sub_category_mask]\n",
    "    pages_df_list.append( pages_df)\n",
    "\n",
    "    sub_categories = category_pages_df[ sub_category_mask].title.str.replace( 'Category:', '').tolist()    ## Create list of all sub-category names ( Category: <name>), remove the preface                \n",
    "    categories_pageid_dict[ category] = pages_df.pageid\n",
    "    #print( 'added category to dict - {}'.format(category))\n",
    "    n_sub_categories = sum( sub_category_mask)  ## Number of sub-categories belong to category\n",
    "\n",
    "    if n_sub_categories > 0:\n",
    "        for sub_category in sub_categories:  ## recursively, one at a time\n",
    "            #if sub_category not in categories_pageid_dict:  ## skip categories already visited\n",
    "            try:\n",
    "                #print('New sub-category: {}'.format( sub_category) )\n",
    "                if sub_category in categories_pageid_dict.keys():\n",
    "                    print( '***Category: {} already looked at'.format( sub_category))\n",
    "                    continue\n",
    "\n",
    "                #print('done')\n",
    "                if sub_category not in categories_pageid_dict.keys():\n",
    "                    sub_category_pages = gather_articles( sub_category, count + 1 )[0]\n",
    "                    categories_pageid_dict[ sub_category] = sub_category_pages.pageid\n",
    "                    pages_df_list.append( sub_category_pages  )\n",
    "                    print( 'New sub-category added to dict: {}'.format( sub_category))\n",
    "                \n",
    "\n",
    "            except: \n",
    "                \n",
    "                #except:\n",
    "                print( '+++Category: {} is empty'.format(sub_category) )\n",
    "                continue\n",
    "            #if sub_category in categories_pageid_dict: # \n",
    "            #    print( '***Category: {} already looked at'.format( sub_category))\n",
    "            #    continue\n",
    "            #except: \n",
    "            #    print( '+++Category: {} is empty'.format(sub_category) )\n",
    "            #    continue\n",
    "            \n",
    "                \n",
    "\n",
    "    pages_df = pd.concat( pages_df_list)\n",
    "    #pages_df.reset_index()\n",
    "    return pages_df, categories_pageid_dict\n",
    "\n",
    "    #return 'Empty Category'\n",
    "\n",
    "\n",
    "#pages_df_list.append(  category_pages_df[~sub_category_mask].pageid.apply( grab_content ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NEW,  Added error handling for empty category\n",
    "\n",
    "def gather_articles( category, categories_pageid_dict = {}):  #  used_subcategories = [] \n",
    "    '''Collect all articles that belong to a category, including articles found in sub-categories.\n",
    "        This process is performed recursively to find all relevant articles in the domain space'''\n",
    "    \n",
    "    category_pages_df = request_category( category)  ## load dataframe of pages contained in category\n",
    "    \n",
    "    sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "\n",
    "    pages_df_list = []\n",
    "    pages_df = category_pages_df[ ~sub_category_mask]\n",
    "    pages_df_list.append( pages_df)\n",
    "\n",
    "    sub_categories = category_pages_df[ sub_category_mask].title.str.replace( 'Category:', '').tolist()    ## Create list of all sub-category names ( Category: <name>), remove the preface                \n",
    "    categories_pageid_dict[ category] = pages_df.pageid\n",
    "    #print( 'added category to dict - {}'.format(category))\n",
    "    n_sub_categories = sum( sub_category_mask)  ## Number of sub-categories belong to category\n",
    "\n",
    "    if n_sub_categories > 0:\n",
    "        for sub_category in sub_categories:  ## recursively, one at a time\n",
    "            #if sub_category not in categories_pageid_dict:  ## skip categories already visited\n",
    "            #try:\n",
    "                #print('New sub-category: {}'.format( sub_category) )\n",
    "            if sub_category in categories_pageid_dict:\n",
    "                print( '***Category: {} already looked at'.format( sub_category))\n",
    "                continue\n",
    "\n",
    "                #print('done')\n",
    "                \n",
    "                \n",
    "            #print('new subcat: {}'.format(sub_category not in categories_pageid_dict.keys()) )\n",
    "            #except:\n",
    "            if sub_category not in categories_pageid_dict:\n",
    "                try:\n",
    "                    print('new sub_category: {}'.format(sub_category) )\n",
    "                    print( 'already collected subcategories: {}'.format( categories_pageid_dict.keys() ) )\n",
    "                    store = gather_articles( sub_category, categories_pageid_dict)\n",
    "                    sub_category_pages = store[0] #, count + 1 )[0]\n",
    "                    categories_pageid_dict = store[1] #, count + 1 )[0]\n",
    "                    categories_pageid_dict[ sub_category] = sub_category_pages.pageid\n",
    "                    pages_df_list.append( sub_category_pages  )\n",
    "                    print( 'New sub-category added to dict: {}'.format( sub_category))\n",
    "\n",
    "                except Exception as N:\n",
    "                    print( 'or came here due to {}'.format( N))\n",
    "                    print( '+++Category: {} is empty'.format(sub_category) )\n",
    "                    continue\n",
    "            #if sub_category in categories_pageid_dict: # \n",
    "            #    print( '***Category: {} already looked at'.format( sub_category))\n",
    "            #    continue\n",
    "            #except: \n",
    "            #    print( '+++Category: {} is empty'.format(sub_category) )\n",
    "            #    continue\n",
    "            \n",
    "                \n",
    "\n",
    "    pages_df = pd.concat( pages_df_list)\n",
    "    #pages_df.reset_index()\n",
    "    return pages_df, categories_pageid_dict\n",
    "\n",
    "    #return 'Empty Category'\n",
    "\n",
    "\n",
    "#pages_df_list.append(  category_pages_df[~sub_category_mask].pageid.apply( grab_content ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NEWEST\n",
    "\n",
    "## NEW,  Added error handling for empty category\n",
    "\n",
    "def gather_articles( category, categories_pageid_dict = {}):  #  used_subcategories = [] \n",
    "    '''Collect all articles that belong to a category, including articles found in sub-categories.\n",
    "        This process is performed recursively to find all relevant articles in the domain space'''\n",
    "    \n",
    "    category_pages_df = request_category( category)  ## load dataframe of pages contained in category\n",
    "    \n",
    "    sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "\n",
    "    pages_df_list = []\n",
    "    pages_df = category_pages_df[ ~sub_category_mask]\n",
    "    pages_df_list.append( pages_df)\n",
    "    if category in categories_pageid_dict:\n",
    "        print( '***Category: {} already looked at'.format( sub_category))\n",
    "        continue\n",
    "    if category not in categories_pageid_dict:\n",
    "        categories_pageid_dict[ category] = pages_df.pageid\n",
    "        \n",
    "    \n",
    "    sub_categories = category_pages_df[ sub_category_mask].title.str.replace( 'Category:', '').tolist()    ## Create list of all sub-category names ( Category: <name>), remove the preface                \n",
    "    categories_pageid_dict[ category] = pages_df.pageid\n",
    "    #print( 'added category to dict - {}'.format(category))\n",
    "    n_sub_categories = sum( sub_category_mask)  ## Number of sub-categories belong to category\n",
    "\n",
    "    if n_sub_categories > 0:\n",
    "        for sub_category in sub_categories:  ## recursively, one at a time\n",
    "            try:\n",
    "                sub_categoriy_pages, categories_pageid_dict = gather_articles( sub_category, categories_pageid_dict)\n",
    "                \n",
    "                categories_pageid_dict[ sub_category] = sub_category_pages.pageid    \n",
    "            \n",
    "            if sub_category not in categories_pageid_dict:  ## skip categories already visited\n",
    "            #try:\n",
    "                #print('New sub-category: {}'.format( sub_category) )\n",
    "            if sub_category in categories_pageid_dict:\n",
    "                print( '***Category: {} already looked at'.format( sub_category))\n",
    "                continue\n",
    "\n",
    "                #print('done')\n",
    "                \n",
    "                \n",
    "            #print('new subcat: {}'.format(sub_category not in categories_pageid_dict.keys()) )\n",
    "            #except:\n",
    "            if sub_category not in categories_pageid_dict:\n",
    "                try:\n",
    "                    print('new sub_category: {}'.format(sub_category) )\n",
    "                    print( 'already collected subcategories: {}'.format( categories_pageid_dict.keys() ) )\n",
    "                    store = gather_articles( sub_category, categories_pageid_dict)\n",
    "                    sub_category_pages = store[0] #, count + 1 )[0]\n",
    "                    categories_pageid_dict = store[1] #, count + 1 )[0]\n",
    "                    categories_pageid_dict[ sub_category] = sub_category_pages.pageid\n",
    "                    pages_df_list.append( sub_category_pages  )\n",
    "                    print( 'New sub-category added to dict: {}'.format( sub_category))\n",
    "\n",
    "                except Exception as N:\n",
    "                    print( 'or came here due to {}'.format( N))\n",
    "                    print( '+++Category: {} is empty'.format(sub_category) )\n",
    "                    continue\n",
    "            #if sub_category in categories_pageid_dict: # \n",
    "            #    print( '***Category: {} already looked at'.format( sub_category))\n",
    "            #    continue\n",
    "            #except: \n",
    "            #    print( '+++Category: {} is empty'.format(sub_category) )\n",
    "            #    continue\n",
    "            \n",
    "                \n",
    "\n",
    "    pages_df = pd.concat( pages_df_list)\n",
    "    #pages_df.reset_index()\n",
    "    return pages_df, categories_pageid_dict\n",
    "\n",
    "    #return 'Empty Category'\n",
    "\n",
    "\n",
    "#pages_df_list.append(  category_pages_df[~sub_category_mask].pageid.apply( grab_content ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grab_content( page_id):\n",
    "    try:\n",
    "        page_content = wikipedia.WikipediaPage(pageid = page_id).content\n",
    "    except: \n",
    "        page_content = ''\n",
    "    return page_content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning\n",
      "Applied machine learning\n",
      "Artificial neural networks\n",
      "Deep learning\n",
      "Neural network software\n",
      "Bayesian networks\n",
      "Classification algorithms\n",
      "Artificial neural networks\n",
      "Deep learning\n",
      "Neural network software\n",
      "Decision trees\n",
      "Ensemble learning\n",
      "Cluster analysis\n",
      "Cluster analysis algorithms\n",
      "Clustering criteria\n",
      "Computational learning theory\n",
      "Artificial intelligence conferences\n",
      "Data mining and machine learning software\n",
      "Social network analysis software\n",
      "Datasets in machine learning\n",
      "Datasets in computer vision\n",
      "Dimension reduction\n",
      "Factor analysis\n",
      "Ensemble learning\n",
      "Evolutionary algorithms\n",
      "Gene expression programming\n",
      "Genetic algorithms\n",
      "Artificial immune systems\n",
      "Gene expression programming\n",
      "Genetic programming\n",
      "Nature-inspired metaheuristics\n",
      "Genetic programming\n",
      "Inductive logic programming\n",
      "Kernel methods for machine learning\n",
      "Support vector machines\n",
      "Latent variable models\n",
      "Factor analysis\n",
      "Structural equation models\n",
      "Learning in computer vision\n",
      "Log-linear models\n",
      "Loss functions\n",
      "Machine learning algorithms\n",
      "Genetic algorithms\n",
      "Artificial immune systems\n",
      "Gene expression programming\n",
      "Machine learning portal\n",
      "Machine learning task\n",
      "Markov models\n",
      "Hidden Markov models\n",
      "Markov networks\n",
      "Machine learning researchers\n",
      "Semisupervised learning\n",
      "Statistical natural language processing\n",
      "Language modeling\n",
      "Structured prediction\n",
      "Graphical models\n",
      "Bayesian networks\n",
      "Causal inference\n",
      "Markov networks\n",
      "Supervised learning\n",
      "Support vector machines\n",
      "Unsupervised learning\n"
     ]
    }
   ],
   "source": [
    "## Original\n",
    "\n",
    "ml_articles, ml_categories_pageid_dict = gather_articles( 'machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1606"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( ml_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ml_categories_pageid_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_categories_pageid_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## New\n",
    "\n",
    "ml_articles1, ml_categories_pageid_dict1 = gather_articles( 'machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_articles, bs_categories_pageid_dict = gather_articles( 'Business_software')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len( categories_pageid_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories_pageid_dict['Latent variable models']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.reset_index(inplace = True)\n",
    "ml_articles\n",
    "\n",
    "\n",
    "ml_articles = ml_articles.drop_duplicates().reset_index(drop = True)\n",
    "ml_articles.loc[:, 'content'] = ml_articles.pageid.apply( grab_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pageids = ml_articles.pageid\n",
    "\n",
    "categories_pageid_dict\n",
    "\n",
    "pageid_categories = {} \n",
    "\n",
    "for pid in pageids:\n",
    "    pageid_categories[ pid] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_articles.loc[:, 'category'] = 'machine learning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ml_articles, categories_pageid_dict = gather_articles( 'machine learning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_pages = request_category( 'business software')\n",
    "\n",
    "sub_category_mask = bs_pages.title.str.contains('Category:')\n",
    "\n",
    "bs_pages[ sub_category_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_pages_sub1 = request_category( 'Administrative software')\n",
    "\n",
    "bs_pages_sub1.head()\n",
    "sub_category_mask = bs_pages_sub1.title.str.contains('Category:')\n",
    "\n",
    "print( bs_pages_sub1[ sub_category_mask])\n",
    "print( bs_pages_sub1[~sub_category_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = 'Club software'\n",
    "\n",
    "bs_pages_sub1 = request_category( category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_pages_sub1.empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs_pages_sub2 = request_category( 'Business simulation games')\n",
    "\n",
    "bs_pages_sub2.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = category_pages_df.title.str.contains('Category:')  ## row mask for only sub-categories\n",
    "print(category)\n",
    "pages_df_list = []\n",
    "categories_pageid_dict = {}\n",
    "\n",
    "pages_df = category_pages_df[ ~sub_category_mask]\n",
    "pages_df_list.append( pages_df)\n",
    "\n",
    "sub_categories = category_pages_df[ sub_category_mask].title.str.replace( 'Category:', '').tolist()    ## Create list of all sub-category names ( Category: <name>), remove the preface                \n",
    "categories_pageid_dict[ category] = pages_df.pageid\n",
    "n_sub_categories = sum( sub_category_mask)  ## Number of sub-categories belong to category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "food_articles, food_categories_pageid_dict = gather_articles( 'Foods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = category_pages_df.title.str.contains( 'Category:')\n",
    "category_pages_df[ sub_category_mask].title.replace( 'Category:', '').tolist()\n",
    "\n",
    "len( category_pages_df[ ~sub_category_mask].pageid.tolist()), len(category_pages_df[ ~sub_category_mask].pageid.unique() )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def request_category( category, sub_category = False):  ## return\n",
    "    '''Request from wikipedia API for category pages (articles, subcategories) \n",
    "            return:  JSON object with category pages  '''\n",
    "    if sub_category:\n",
    "        cat_tag = '&cmtitle=Category:' + sub_category ## append category to cat_tag\n",
    "    else: \n",
    "        cat_tag = '&cmtitle=Category:' + category ## append category to cat_tag\n",
    "    \n",
    "    base_url = 'https://en.wikipedia.org/w/api.php'\n",
    "    action_tag = \"?action=query&list=categorymembers&cmlimit=max\" ## fetch all category members (pages, subcategories)\n",
    "    #category_tag =  cat_tag#'&cmtitle=Category:' + category ## append category to cat_tag\n",
    "    parameters_tag = \"&format=json&prop=info|categories|links\" #&prop=categories|links|info\" ## return in json format\n",
    "    request_call = base_url + action_tag + cat_tag + parameters_tag ## concatenate base_url with request tags\n",
    "    request = requests.get( request_call)  ## request HTTP results\n",
    "    \n",
    "    category_pages = request.json()['query']['categorymembers']  ## list object containing category pages ( articles, sub-categories)\n",
    "    \n",
    "    pages = {}\n",
    "    for i, page_info in enumerate( category_pages):\n",
    "        page_id = page_info['pageid']\n",
    "        page_title = page_info['title']\n",
    "        if sub_category:\n",
    "            pages[i] ={'category': category, 'sub-category': sub_category, 'pageid': page_id, 'title': page_title, 'content':np.nan } \n",
    "        else:\n",
    "            pages[i] ={'category': category, 'sub-category': None, 'pageid': page_id, 'title': page_title, 'content':np.nan } \n",
    "    \n",
    "    pages_df = pd.DataFrame.from_dict( pages, orient = 'index')\n",
    "    \n",
    "    pages_df['title']\n",
    "    \n",
    "    return pages_df\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_content( page_df, condition = True):\n",
    "    \n",
    "    category = page_df.category.unique()[0]\n",
    "\n",
    "    sub_category_mask = page_df.title.str.contains( 'Category:')  ## row mask \n",
    "    \n",
    "    new_articles_mask = ~sub_category_mask & page_df.content.isnull()\n",
    "     \n",
    "    sub_category_indices = page_df[sub_category_mask].index.tolist()\n",
    "    ## gather all the article content for the each page in the category, excluding the sub_categories\n",
    "    page_df.loc[new_articles_mask, 'content'] = page_df[ new_articles_mask ].apply( lambda x: grab_content( x.pageid), axis = 1 )\n",
    "    \n",
    "    n_sub_categories = sum( sub_category_mask)\n",
    "    if n_sub_categories == 0:\n",
    "        condition = False\n",
    "        return page_df\n",
    "    \n",
    "    \n",
    "    while condition:\n",
    "        \n",
    "        subCat_indice = sub_category_indices[0] ## grab the first one\n",
    "        \n",
    "        \n",
    "        subCat = page_df.iloc[subCat_indice,:]['title'].split('Category:')[1] # subCat = \n",
    "        \n",
    "        page_df = page_df.append( request_category( category, subCat ), ignore_index= True)\n",
    "        \n",
    "        \n",
    "        page_df.drop( page_df.index[ subCat_indice], inplace = True )  ## Remove the original page\n",
    "        \n",
    "        gather_content( page_df)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df = request_category('Machine_learning')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.tail(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_df = gather_content( page_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.category.unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = page_df.title.str.contains( 'Category:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.shape, sum( sub_category_mask), sum( ~sub_category_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = page_df_test.title.str.contains( 'Category:')\n",
    "\n",
    "sum(~sub_category_mask), page_df_test.content.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_articles_mask = ~sub_category_mask & page_df_test.content.isnull()\n",
    "sum(new_articles_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = page_df.title.str.contains( 'Category:')\n",
    "\n",
    "new_articles_mask = ~sub_category_mask & page_df.content.isnull()\n",
    "    \n",
    "n_articles = sum( ~sub_category_mask)\n",
    "n_sub_categories = sum( sub_category_mask)\n",
    "\n",
    "#print( '{} requests to be made'.format( n_articles * n_sub_categories) )\n",
    "## First gather all the article content for the each page in the category\n",
    "page_df.loc[~sub_category_mask, 'content'] = page_df[ ~sub_category_mask ].apply( lambda x: grab_content( x.pageid), axis = 1 )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.tail(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = page_df.category.unique()[0]\n",
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_indices = page_df[sub_category_mask].index.tolist()\n",
    "\n",
    "\n",
    "\n",
    "subCat_indice = sub_category_indices[0] ## grab the first one\n",
    "print(subCat_indice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subCat = page_df.iloc[subCat_indice,:]['title'].split('Category:')[1] # subCat = \n",
    "print( subCat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_pages_df = request_category( category, subCat )\n",
    "\n",
    "page_df = page_df.append( sub_category_pages_df, ignore_index= True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.drop( page_df.index[262:], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.tail(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print( page_df.loc[ subCat_indice, :])\n",
    "\n",
    "\n",
    "page_df.drop( page_df.index[ subCat_indice], inplace = True )  ## Remove the original page\n",
    "page_df.tail(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = page_df.title.str.contains( 'Category:')  ## row mask "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum(sub_category_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "new_articles_mask = ~sub_category_mask & page_df.content.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df[new_articles_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.content.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category = page_df.category.unique()[0]\n",
    "\n",
    "sub_category_indices = df[sub_category_mask].index.tolist()\n",
    "\n",
    "subCat_indice = sub_category_indices[0] ## grab the first one\n",
    "print(subCat_indice)\n",
    "\n",
    "\n",
    "subCat = page_df.iloc[subCat_indice,:]['title'].split('Category:')[1] # subCat = \n",
    "print( subCat)\n",
    "request_category( category, subCat )\n",
    "\n",
    "#page_df = page_df.append( request_category( category, subCat ), ignore_index= True) # \n",
    "\n",
    "#print( page_df.loc[ subCat_indice, :])\n",
    "\n",
    "#page_df.tail()\n",
    "#page_df.drop( page_df.index[ sub_Cat_indice] )  ## Remove the original page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.iloc[455,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df[ page_df['sub-category'] == 'Applied machine learning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df['sub-category'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_df.iloc[198,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_sub_categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range( ):\n",
    "    page_df.append( request_category( page_df.category.unique()[0], df[sub_category_mask].iloc[i,:]['title'].split('Category:')[1]), ignore_index= True)            \n",
    "    # page_df.drop()  ## remove original page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_indices = df[sub_category_mask].index.tolist()\n",
    "\n",
    "subCat_indice = sub_category_indices[0] ## grab the first one\n",
    "\n",
    "subCat = page_df.iloc[subCat_indice,:]['title'].split('Category:')[1] # subCat = \n",
    "        \n",
    "page_df.append( request_category( category, subCat ), ignore_index= True)\n",
    "\n",
    "\n",
    "page_df.drop( page_df.index[ sub_Cat_indice] )  ## Remove the original page\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grab_content( 39945557)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "~sub_category_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "df.loc[~sub_category_mask, 'content'] = df[ ~sub_category_mask ].apply( lambda x: grab_content( x.pageid), axis = 1 )\n",
    "#sub_df.apply( lambda x: grab_content(x.pageid), axis = 1) # grab_content("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[sub_category_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[sub_category_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[sub_category_mask].apply( lambda x: request_category('Machine_learning', x.title.split('Category:')[1]), axis = 1 )#, axis = 1)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.append(request_category( 'Machine_learning', df[sub_category_mask].apply( lambda x: x.title.split('Category:')[1]), ignore_index= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.append(request_category( 'Machine_learning', df[sub_category_mask].iloc[0,:]['title'].split('Category:')[1]), ignore_index= True)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[sub_category_mask].apply(  lambda x: request_category( x['title'].split('Category:')[1]), axis = 1)   # \n",
    "## \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[sub_category_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_category_mask = df.title.str.contains( 'Category:')\n",
    "\n",
    "\n",
    "article_df = df[ ~sub_category_mask ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df = article_df.loc[:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df.loc[:, 'content'] = sub_df.apply( lambda x: grab_content(x.pageid), axis = 1) # grab_content("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_json = request_category('Machine_learning').json()\n",
    "\n",
    "ml_pages  = ml_json['query']['categorymembers']  ## List object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ml_pages  = ml_json['query']['categorymembers']  ## List object\n",
    "N_pages = len(ml_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_pages[-1]['title'].split('Category:')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml_json['query'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages = {}\n",
    "for i, page_info in enumerate( category_pages):\n",
    "    page_id = page_info['pageid']\n",
    "    page_title = page_info['title']\n",
    "    \n",
    "    pages[i] ={'pageid': page_id, 'title': page_title, 'content': page_content, 'category': category} \n",
    "    \n",
    "pages_df = pd.DataFrame.from_dict( pages, orient = 'index')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_content( category, category_pages):\n",
    "    \n",
    "    request_category( category).json()\n",
    "    \n",
    "\n",
    "    pages = {}\n",
    "\n",
    "    for i, page_info in enumerate( category_pages):\n",
    "\n",
    "        page_type = page_info['ns']\n",
    "        page_id = page_info['pageid']\n",
    "        page_title = page_info['title']\n",
    "\n",
    "        if page_type == 0:  ## category\n",
    "            \n",
    "            page_content = wikipedia.WikipediaPage(pageid = page_id).content\n",
    "\n",
    "            pages[i] ={'pageid': page_id, 'title': page_title, 'conent': page_content, 'category':} \n",
    "            \n",
    "        else:  ## sub-category\n",
    "            sub_category = page_title.split('Category:')[1]\n",
    "            \n",
    "            sub_category_pages = request_category( sub_category).json()['query']['categorymembers']\n",
    "            \n",
    "            gather_content( category, sub_category_pages)\n",
    "            \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gather_content( category, category_pages):\n",
    "    \n",
    "    \n",
    "\n",
    "    pages = {}\n",
    "\n",
    "    for i, page_info in enumerate( ml_pages[0:10]):\n",
    "\n",
    "        page_type = page_info['ns']\n",
    "        page_id = page_info['pageid']\n",
    "        page_title = page_info['title']\n",
    "\n",
    "        if page_type == 14:  ## sub-category\n",
    "            \n",
    "            sub_category = page_title.split('Category:')[1]\n",
    "            \n",
    "            sub_category_json = request_category( sub_category).json()\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        #else:  ## article\n",
    "            #page_content = wikipedia.WikipediaPage(pageid = page_id).content\n",
    "\n",
    "            #pages[i] ={'pageid': page_id, 'title': page_title, 'conent': page_content, 'category':} \n",
    "        \n",
    "#pages        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict( pages, orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Get all the pages in a Category\n",
    "\n",
    "catJson = ml.json() ## dict\n",
    "catJson.keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catPages = catJson['query']['categorymembers']\n",
    "print( len( catPages))\n",
    "print( catPages[0:5], sep = '\\n' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = {}\n",
    "\n",
    "subcats = {}\n",
    "\n",
    "for i, page in enumerate( catPages):\n",
    "    \n",
    "    pageid = page['pageid']\n",
    "    title = page['title']\n",
    "    \n",
    "    if 'Category' not in title:\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#wikipedia.WikipediaPage(pageid = 50222574).links\n",
    "wikipedia.WikipediaPage(pageid = 39945557)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = 'https://en.wikipedia.org/w/api.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "action = \"?action=query&list=categorymembers&cmlimit=max\" ## &generator=allpages |allpages\n",
    "#action = \"?action=mobileview\"\n",
    "parameters = \"&format=json&prop=categories|links|info\" #  \" # &sections=all &rvprop=content\n",
    "category = '&cmtitle=Category:'\n",
    "#titles = \"&titles=\"\n",
    "#page = \"&page=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#category = \"Machine_learning\"\n",
    "\n",
    "url = base_url + action + parameters + category + 'Category:Machine_learning'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml = requests.get( url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ml.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
